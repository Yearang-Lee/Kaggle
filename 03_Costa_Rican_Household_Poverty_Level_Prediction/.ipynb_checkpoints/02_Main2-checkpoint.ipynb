{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고 커널 : https://www.kaggle.com/youhanlee/3250feats-532-feats-using-shap-lb-0-436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\lsl\\anaconda3\\lib\\site-packages (0.34.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from shap) (0.25.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from shap) (1.16.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from shap) (1.4.1)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from shap) (4.36.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from shap) (0.21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from pandas->shap) (2019.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (0.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->shap) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: featuretools in c:\\users\\lsl\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: psutil>=5.4.8 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (5.6.3)\n",
      "Requirement already satisfied: scipy>=0.13.3 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (1.4.1)\n",
      "Requirement already satisfied: tqdm>=4.32.0 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (4.36.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (1.16.5)\n",
      "Requirement already satisfied: dask[dataframe]>=1.1.0 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (2.5.2)\n",
      "Requirement already satisfied: pandas>=0.24.1 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (0.25.1)\n",
      "Requirement already satisfied: distributed>=1.24.2 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (2.5.2)\n",
      "Requirement already satisfied: cloudpickle>=0.4.0 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (1.2.2)\n",
      "Requirement already satisfied: click>=7.0.0 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (7.0)\n",
      "Requirement already satisfied: pyyaml>=3.12 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from featuretools) (5.1.2)\n",
      "Requirement already satisfied: fsspec>=0.5.1; extra == \"dataframe\" in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from dask[dataframe]>=1.1.0->featuretools) (0.5.2)\n",
      "Requirement already satisfied: toolz>=0.7.3; extra == \"dataframe\" in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from dask[dataframe]>=1.1.0->featuretools) (0.10.0)\n",
      "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from dask[dataframe]>=1.1.0->featuretools) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from pandas>=0.24.1->featuretools) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from pandas>=0.24.1->featuretools) (2019.3)\n",
      "Requirement already satisfied: msgpack in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from distributed>=1.24.2->featuretools) (0.6.1)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from distributed>=1.24.2->featuretools) (2.1.0)\n",
      "Requirement already satisfied: tblib in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from distributed>=1.24.2->featuretools) (1.4.0)\n",
      "Requirement already satisfied: zict>=0.1.3 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from distributed>=1.24.2->featuretools) (1.0.0)\n",
      "Requirement already satisfied: tornado>=5 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from distributed>=1.24.2->featuretools) (6.0.3)\n",
      "Requirement already satisfied: locket in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[dataframe]>=1.1.0->featuretools) (0.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.24.1->featuretools) (1.12.0)\n",
      "Requirement already satisfied: heapdict in c:\\users\\lsl\\anaconda3\\lib\\site-packages (from zict>=0.1.3->distributed>=1.24.2->featuretools) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(font_scale=2.2)\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import featuretools as ft\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (9557, 143)    df_test shape:  (23856, 142)\n"
     ]
    }
   ],
   "source": [
    "print('df_train shape:', df_train.shape, '  ', 'df_test shape: ', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...          100    1849               1        100             0   \n",
       "1     0  ...          144    4489               1        144             0   \n",
       "2     0  ...          121    8464               1          0             0   \n",
       "3     0  ...           81     289              16        121             4   \n",
       "4     0  ...          121    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  \n",
       "0         1.000000            0.0      100.0   1849       4  \n",
       "1         1.000000           64.0      144.0   4489       4  \n",
       "2         0.250000           64.0      121.0   8464       4  \n",
       "3         1.777778            1.0      121.0    289       4  \n",
       "4         1.777778            1.0      121.0   1369       4  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>age</th>\n",
       "      <th>SQBescolari</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_2f6873615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_1c78846d2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>256</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_e5442cf6a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>41</td>\n",
       "      <td>289</td>\n",
       "      <td>1681</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>272.25</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_a8db26a79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>256</td>\n",
       "      <td>3481</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>256.00</td>\n",
       "      <td>3481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_a62966799</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>121</td>\n",
       "      <td>324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>64.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_2f6873615       NaN       0      5       0     1       1     0    NaN   \n",
       "1  ID_1c78846d2       NaN       0      5       0     1       1     0    NaN   \n",
       "2  ID_e5442cf6a       NaN       0      5       0     1       1     0    NaN   \n",
       "3  ID_a8db26a79       NaN       0     14       0     1       1     1    1.0   \n",
       "4  ID_a62966799  175000.0       0      4       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  age  SQBescolari  SQBage  SQBhogar_total  SQBedjefe  \\\n",
       "0     1  ...    4            0      16               9          0   \n",
       "1     1  ...   41          256    1681               9          0   \n",
       "2     1  ...   41          289    1681               9          0   \n",
       "3     0  ...   59          256    3481               1        256   \n",
       "4     0  ...   18          121     324               1          0   \n",
       "\n",
       "   SQBhogar_nin  SQBovercrowding  SQBdependency  SQBmeaned  agesq  \n",
       "0             1             2.25           0.25     272.25     16  \n",
       "1             1             2.25           0.25     272.25   1681  \n",
       "2             1             2.25           0.25     272.25   1681  \n",
       "3             0             1.00           0.00     256.00   3481  \n",
       "4             1             0.25          64.00        NaN    324  \n",
       "\n",
       "[5 rows x 142 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Make description df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = [\n",
    "(\"v2a1\",\" Monthly rent payment\"),\n",
    "(\"hacdor\",\" =1 Overcrowding by bedrooms\"),\n",
    "(\"rooms\",\"  number of all rooms in the house\"),\n",
    "(\"hacapo\",\" =1 Overcrowding by rooms\"),\n",
    "(\"v14a\",\" =1 has toilet in the household\"),\n",
    "(\"refrig\",\" =1 if the household has refrigerator\"),\n",
    "(\"v18q\",\" owns a tablet\"),\n",
    "(\"v18q1\",\" number of tablets household owns\"),\n",
    "(\"r4h1\",\" Males younger than 12 years of age\"),\n",
    "(\"r4h2\",\" Males 12 years of age and older\"),\n",
    "(\"r4h3\",\" Total males in the household\"),\n",
    "(\"r4m1\",\" Females younger than 12 years of age\"),\n",
    "(\"r4m2\",\" Females 12 years of age and older\"),\n",
    "(\"r4m3\",\" Total females in the household\"),\n",
    "(\"r4t1\",\" persons younger than 12 years of age\"),\n",
    "(\"r4t2\",\" persons 12 years of age and older\"),\n",
    "(\"r4t3\",\" Total persons in the household\"),\n",
    "(\"tamhog\",\" size of the household\"),\n",
    "(\"tamviv\",\" number of persons living in the household\"),\n",
    "(\"escolari\",\" years of schooling\"),\n",
    "(\"rez_esc\",\" Years behind in school\"),\n",
    "(\"hhsize\",\" household size\"),\n",
    "(\"paredblolad\",\" =1 if predominant material on the outside wall is block or brick\"),\n",
    "(\"paredzocalo\",\" =1 if predominant material on the outside wall is socket (wood, zinc or absbesto\"),\n",
    "(\"paredpreb\",\" =1 if predominant material on the outside wall is prefabricated or cement\"),\n",
    "(\"pareddes\",\" =1 if predominant material on the outside wall is waste material\"),\n",
    "(\"paredmad\",\" =1 if predominant material on the outside wall is wood\"),\n",
    "(\"paredzinc\",\" =1 if predominant material on the outside wall is zink\"),\n",
    "(\"paredfibras\",\" =1 if predominant material on the outside wall is natural fibers\"),\n",
    "(\"paredother\",\" =1 if predominant material on the outside wall is other\"),\n",
    "(\"pisomoscer\",\" =1 if predominant material on the floor is mosaic ceramic   terrazo\"),\n",
    "(\"pisocemento\",\" =1 if predominant material on the floor is cement\"),\n",
    "(\"pisoother\",\" =1 if predominant material on the floor is other\"),\n",
    "(\"pisonatur\",\" =1 if predominant material on the floor is  natural material\"),\n",
    "(\"pisonotiene\",\" =1 if no floor at the household\"),\n",
    "(\"pisomadera\",\" =1 if predominant material on the floor is wood\"),\n",
    "(\"techozinc\",\" =1 if predominant material on the roof is metal foil or zink\"),\n",
    "(\"techoentrepiso\",\" =1 if predominant material on the roof is fiber cement,   mezzanine \"),\n",
    "(\"techocane\",\" =1 if predominant material on the roof is natural fibers\"),\n",
    "(\"techootro\",\" =1 if predominant material on the roof is other\"),\n",
    "(\"cielorazo\",\" =1 if the house has ceiling\"),\n",
    "(\"abastaguadentro\",\" =1 if water provision inside the dwelling\"),\n",
    "(\"abastaguafuera\",\" =1 if water provision outside the dwelling\"),\n",
    "(\"abastaguano\",\" =1 if no water provision\"),\n",
    "(\"public\",\" =1 electricity from CNFL,  ICE, ESPH/JASEC\"),\n",
    "(\"planpri\",\" =1 electricity from private plant\"),\n",
    "(\"noelec\",\" =1 no electricity in the dwelling\"),\n",
    "(\"coopele\",\" =1 electricity from cooperative\"),\n",
    "(\"sanitario1\",\" =1 no toilet in the dwelling\"),\n",
    "(\"sanitario2\",\" =1 toilet connected to sewer or cesspool\"),\n",
    "(\"sanitario3\",\" =1 toilet connected to  septic tank\"),\n",
    "(\"sanitario5\",\" =1 toilet connected to black hole or letrine\"),\n",
    "(\"sanitario6\",\" =1 toilet connected to other system\"),\n",
    "(\"energcocinar1\",\" =1 no main source of energy used for cooking (no kitchen)\"),\n",
    "(\"energcocinar2\",\" =1 main source of energy used for cooking electricity\"),\n",
    "(\"energcocinar3\",\" =1 main source of energy used for cooking gas\"),\n",
    "(\"energcocinar4\",\" =1 main source of energy used for cooking wood charcoal\"),\n",
    "(\"elimbasu1\",\" =1 if rubbish disposal mainly by tanker truck\"),\n",
    "(\"elimbasu2\",\" =1 if rubbish disposal mainly by botan hollow or buried\"),\n",
    "(\"elimbasu3\",\" =1 if rubbish disposal mainly by burning\"),\n",
    "(\"elimbasu4\",\" =1 if rubbish disposal mainly by throwing in an unoccupied space\"),\n",
    "(\"elimbasu5\",\" =1 if rubbish disposal mainly by throwing in river,   creek or sea\"),\n",
    "(\"elimbasu6\",\" =1 if rubbish disposal mainly other\"),\n",
    "(\"epared1\",\" =1 if walls are bad\"),\n",
    "(\"epared2\",\" =1 if walls are regular\"),\n",
    "(\"epared3\",\" =1 if walls are good\"),\n",
    "(\"etecho1\",\" =1 if roof are bad\"),\n",
    "(\"etecho2\",\" =1 if roof are regular\"),\n",
    "(\"etecho3\",\" =1 if roof are good\"),\n",
    "(\"eviv1\",\" =1 if floor are bad\"),\n",
    "(\"eviv2\",\" =1 if floor are regular\"),\n",
    "(\"eviv3\",\" =1 if floor are good\"),\n",
    "(\"dis\",\" =1 if disable person\"),\n",
    "(\"male\",\" =1 if male\"),\n",
    "(\"female\",\" =1 if female\"),\n",
    "(\"estadocivil1\",\" =1 if less than 10 years old\"),\n",
    "(\"estadocivil2\",\" =1 if free or coupled uunion\"),\n",
    "(\"estadocivil3\",\" =1 if married\"),\n",
    "(\"estadocivil4\",\" =1 if divorced\"),\n",
    "(\"estadocivil5\",\" =1 if separated\"),\n",
    "(\"estadocivil6\",\" =1 if widow/er\"),\n",
    "(\"estadocivil7\",\" =1 if single\"),\n",
    "(\"parentesco1\",\" =1 if household head\"),\n",
    "(\"parentesco2\",\" =1 if spouse/partner\"),\n",
    "(\"parentesco3\",\" =1 if son/doughter\"),\n",
    "(\"parentesco4\",\" =1 if stepson/doughter\"),\n",
    "(\"parentesco5\",\" =1 if son/doughter in law\"),\n",
    "(\"parentesco6\",\" =1 if grandson/doughter\"),\n",
    "(\"parentesco7\",\" =1 if mother/father\"),\n",
    "(\"parentesco8\",\" =1 if father/mother in law\"),\n",
    "(\"parentesco9\",\" =1 if brother/sister\"),\n",
    "(\"parentesco10\",\" =1 if brother/sister in law\"),\n",
    "(\"parentesco11\",\" =1 if other family member\"),\n",
    "(\"parentesco12\",\" =1 if other non family member\"),\n",
    "(\"idhogar\",\" Household level identifier\"),\n",
    "(\"hogar_nin\",\" Number of children 0 to 19 in household\"),\n",
    "(\"hogar_adul\",\" Number of adults in household\"),\n",
    "(\"hogar_mayor\",\" # of individuals 65+ in the household\"),\n",
    "(\"hogar_total\",\" # of total individuals in the household\"),\n",
    "(\"dependency\",\" Dependency rate\"),\n",
    "(\"edjefe\",\" years of education of male head of household\"),\n",
    "(\"edjefa\",\" years of education of female head of household\"),\n",
    "(\"meaneduc\",\"average years of education for adults (18+)\"),\n",
    "(\"instlevel1\",\" =1 no level of education\"),\n",
    "(\"instlevel2\",\" =1 incomplete primary\"),\n",
    "(\"instlevel3\",\" =1 complete primary\"),\n",
    "(\"instlevel4\",\" =1 incomplete academic secondary level\"),\n",
    "(\"instlevel5\",\" =1 complete academic secondary level\"),\n",
    "(\"instlevel6\",\" =1 incomplete technical secondary level\"),\n",
    "(\"instlevel7\",\" =1 complete technical secondary level\"),\n",
    "(\"instlevel8\",\" =1 undergraduate and higher education\"),\n",
    "(\"instlevel9\",\" =1 postgraduate higher education\"),\n",
    "(\"bedrooms\",\" number of bedrooms\"),\n",
    "(\"overcrowding\",\" # persons per room\"),\n",
    "(\"tipovivi1\",\" =1 own and fully paid house\"),\n",
    "(\"tipovivi2\",\" =1 own,   paying in installments\"),\n",
    "(\"tipovivi3\",\" =1 rented\"),\n",
    "(\"tipovivi4\",\" =1 precarious\"),\n",
    "(\"tipovivi5\",\" =1 other(assigned\"),\n",
    "(\"computer\",\" =1 if the household has notebook or desktop computer,   borrowed)\"),\n",
    "(\"television\",\" =1 if the household has TV\"),\n",
    "(\"mobilephone\",\" =1 if mobile phone\"),\n",
    "(\"qmobilephone\",\" # of mobile phones\"),\n",
    "(\"lugar1\",\" =1 region Central\"),\n",
    "(\"lugar2\",\" =1 region Chorotega\"),\n",
    "(\"lugar3\",\" =1 region PacÃƒÂ­fico central\"),\n",
    "(\"lugar4\",\" =1 region Brunca\"),\n",
    "(\"lugar5\",\" =1 region Huetar AtlÃƒÂ¡ntica\"),\n",
    "(\"lugar6\",\" =1 region Huetar Norte\"),\n",
    "(\"area1\",\" =1 zona urbana\"),\n",
    "(\"area2\",\" =2 zona rural\"),\n",
    "(\"age\",\" Age in years\"),\n",
    "(\"SQBescolari\",\" escolari squared\"),\n",
    "(\"SQBage\",\" age squared\"),\n",
    "(\"SQBhogar_total\",\" hogar_total squared\"),\n",
    "(\"SQBedjefe\",\" edjefe squared\"),\n",
    "(\"SQBhogar_nin\",\" hogar_nin squared\"),\n",
    "(\"SQBovercrowding\",\" overcrowding squared\"),\n",
    "(\"SQBdependency\",\" dependency squared\"),\n",
    "(\"SQBmeaned\",\" meaned squared\"),\n",
    "(\"agesq\",\" Age squared\"),]\n",
    "\n",
    "description = pd.DataFrame(description, columns=['varname', 'description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>varname</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>v2a1</td>\n",
       "      <td>Monthly rent payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>hacdor</td>\n",
       "      <td>=1 Overcrowding by bedrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rooms</td>\n",
       "      <td>number of all rooms in the house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>hacapo</td>\n",
       "      <td>=1 Overcrowding by rooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>v14a</td>\n",
       "      <td>=1 has toilet in the household</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>SQBhogar_nin</td>\n",
       "      <td>hogar_nin squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>SQBovercrowding</td>\n",
       "      <td>overcrowding squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>SQBdependency</td>\n",
       "      <td>dependency squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>SQBmeaned</td>\n",
       "      <td>meaned squared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>agesq</td>\n",
       "      <td>Age squared</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>141 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             varname                         description\n",
       "0               v2a1                Monthly rent payment\n",
       "1             hacdor         =1 Overcrowding by bedrooms\n",
       "2              rooms    number of all rooms in the house\n",
       "3             hacapo            =1 Overcrowding by rooms\n",
       "4               v14a      =1 has toilet in the household\n",
       "..               ...                                 ...\n",
       "136     SQBhogar_nin                   hogar_nin squared\n",
       "137  SQBovercrowding                overcrowding squared\n",
       "138    SQBdependency                  dependency squared\n",
       "139        SQBmeaned                      meaned squared\n",
       "140            agesq                         Age squared\n",
       "\n",
       "[141 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Check null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>rez_esc</td>\n",
       "      <td>7928</td>\n",
       "      <td>82.954902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>v18q1</td>\n",
       "      <td>7342</td>\n",
       "      <td>76.823271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>v2a1</td>\n",
       "      <td>6860</td>\n",
       "      <td>71.779847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>meaneduc</td>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SQBmeaned</td>\n",
       "      <td>5</td>\n",
       "      <td>0.052318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techozinc</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techoentrepiso</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techocane</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techootro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cielorazo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguadentro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguafuera</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguano</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>planpri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noelec</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>coopele</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total    Percent\n",
       "rez_esc           7928  82.954902\n",
       "v18q1             7342  76.823271\n",
       "v2a1              6860  71.779847\n",
       "meaneduc             5   0.052318\n",
       "SQBmeaned            5   0.052318\n",
       "techozinc            0   0.000000\n",
       "techoentrepiso       0   0.000000\n",
       "techocane            0   0.000000\n",
       "techootro            0   0.000000\n",
       "cielorazo            0   0.000000\n",
       "abastaguadentro      0   0.000000\n",
       "sanitario3           0   0.000000\n",
       "abastaguafuera       0   0.000000\n",
       "abastaguano          0   0.000000\n",
       "public               0   0.000000\n",
       "planpri              0   0.000000\n",
       "noelec               0   0.000000\n",
       "coopele              0   0.000000\n",
       "sanitario1           0   0.000000\n",
       "sanitario2           0   0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if education is \"yes\" and person is head of household, fill with escolari\n",
    "df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefa\"] = df_train.loc[(df_train['edjefa'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"edjefe\"] = df_train.loc[(df_train['edjefe'] == \"yes\") & (df_train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefa\"] = df_test.loc[(df_test['edjefa'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]\n",
    "df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"edjefe\"] = df_test.loc[(df_test['edjefe'] == \"yes\") & (df_test['parentesco1'] == 1), \"escolari\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "df_train.loc[df_train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_train.loc[df_train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "df_test.loc[df_test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "df_test.loc[df_test['edjefe'] == \"yes\", \"edjefe\"] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature with max education of either head of household\n",
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"v14a\"] = 0\n",
    "df_train.loc[(df_train.v14a ==  1) & (df_train.sanitario1 ==  1) & (df_train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"v14a\"] = 0\n",
    "df_test.loc[(df_test.v14a ==  1) & (df_test.sanitario1 ==  1) & (df_test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>v2a1</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>rooms</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>v18q</th>\n",
       "      <th>v18q1</th>\n",
       "      <th>r4h1</th>\n",
       "      <th>...</th>\n",
       "      <th>SQBage</th>\n",
       "      <th>SQBhogar_total</th>\n",
       "      <th>SQBedjefe</th>\n",
       "      <th>SQBhogar_nin</th>\n",
       "      <th>SQBovercrowding</th>\n",
       "      <th>SQBdependency</th>\n",
       "      <th>SQBmeaned</th>\n",
       "      <th>agesq</th>\n",
       "      <th>Target</th>\n",
       "      <th>edjef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>190000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1849</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1849</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4489</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>4489</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>8464</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ID_d671db89c</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>289</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>289</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ID_d56d6f5f5</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1369</td>\n",
       "      <td>16</td>\n",
       "      <td>121</td>\n",
       "      <td>4</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1369</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      v2a1  hacdor  rooms  hacapo  v14a  refrig  v18q  v18q1  \\\n",
       "0  ID_279628684  190000.0       0      3       0     1       1     0    NaN   \n",
       "1  ID_f29eb3ddd  135000.0       0      4       0     1       1     1    1.0   \n",
       "2  ID_68de51c94       NaN       0      8       0     1       1     0    NaN   \n",
       "3  ID_d671db89c  180000.0       0      5       0     1       1     1    1.0   \n",
       "4  ID_d56d6f5f5  180000.0       0      5       0     1       1     1    1.0   \n",
       "\n",
       "   r4h1  ...  SQBage  SQBhogar_total  SQBedjefe  SQBhogar_nin  \\\n",
       "0     0  ...    1849               1        100             0   \n",
       "1     0  ...    4489               1        144             0   \n",
       "2     0  ...    8464               1          0             0   \n",
       "3     0  ...     289              16        121             4   \n",
       "4     0  ...    1369              16        121             4   \n",
       "\n",
       "   SQBovercrowding  SQBdependency  SQBmeaned  agesq  Target  edjef  \n",
       "0         1.000000            0.0      100.0   1849       4    NaN  \n",
       "1         1.000000           64.0      144.0   4489       4    NaN  \n",
       "2         0.250000           64.0      121.0   8464       4    NaN  \n",
       "3         1.777778            1.0      121.0    289       4    NaN  \n",
       "4         1.777778            1.0      121.0   1369       4    NaN  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rez_esc, SQBmeaned  \n",
    "- **rez_esc** : Years behind in school -> filled with 0\n",
    "- **SQBmeaned** : square of the mean years of education of adults (>=18) in the household agesq, Age squared -> same with rez_esc -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc'].fillna(0, inplace=True)\n",
    "df_test['rez_esc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['SQBmeaned'].fillna(0, inplace=True)\n",
    "df_test['SQBmeaned'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### meaneduc\n",
    "- **meaneduc**: average years of education for adults (18+) -> filled with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['meaneduc'].fillna(0, inplace=True)\n",
    "df_test['meaneduc'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v18q1\n",
    "- **v18q1**: number of tablets household owns -> if v18q(Do you own a tablet?) == 1, there are some values. If not, only NaN values in v18q1. See below 3 cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7342\n",
       "1    2215\n",
       "Name: v18q, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['v18q'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **v18q1**: number of tablets household owns -> if v18q == 1, there are some values. If not, only NaN values there. See below two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1586\n",
       "2.0     444\n",
       "3.0     129\n",
       "4.0      37\n",
       "5.0      13\n",
       "6.0       6\n",
       "Name: v18q1, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 1, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: v18q1, dtype: int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[df_train['v18q'] == 0, 'v18q1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v18q1'].fillna(0, inplace=True)\n",
    "df_test['v18q1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **v2a1**: number of tablets household owns -> if tipovivi3(rented?) == 1, there are some values. If not, there are also some values.\n",
    "- NaN value could be replaced by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7821\n",
       "1    1736\n",
       "Name: tipovivi3, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['tipovivi3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 1, 'v2a1'], label='Monthly rent payment of household(rented=1)')\n",
    "sns.kdeplot(df_train.loc[df_train['tipovivi3'] == 0, 'v2a1'], label='Monthly rent payment of household(rented=0)')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['v2a1'].fillna(0, inplace=True)\n",
    "df_test['v2a1'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>edjef</td>\n",
       "      <td>9557</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Target</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>coopele</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noelec</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>planpri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguano</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguafuera</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguadentro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cielorazo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techootro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techocane</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techoentrepiso</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techozinc</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>energcocinar1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef             9557    100.0\n",
       "Target               0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguano          0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario5           0      0.0\n",
       "sanitario6           0      0.0\n",
       "energcocinar1        0      0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_train.isnull().sum() / df_train.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>edjef</td>\n",
       "      <td>23856</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguano</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>coopele</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>noelec</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>planpri</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>public</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguafuera</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>abastaguadentro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>cielorazo</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techootro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techocane</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techoentrepiso</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>techozinc</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sanitario6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>pisonotiene</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>elimbasu5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Total  Percent\n",
       "edjef            23856    100.0\n",
       "abastaguano          0      0.0\n",
       "sanitario2           0      0.0\n",
       "sanitario1           0      0.0\n",
       "coopele              0      0.0\n",
       "noelec               0      0.0\n",
       "planpri              0      0.0\n",
       "public               0      0.0\n",
       "abastaguafuera       0      0.0\n",
       "sanitario5           0      0.0\n",
       "abastaguadentro      0      0.0\n",
       "cielorazo            0      0.0\n",
       "techootro            0      0.0\n",
       "techocane            0      0.0\n",
       "techoentrepiso       0      0.0\n",
       "techozinc            0      0.0\n",
       "sanitario3           0      0.0\n",
       "sanitario6           0      0.0\n",
       "pisonotiene          0      0.0\n",
       "elimbasu5            0      0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = df_test.isnull().sum().sort_values(ascending=False)\n",
    "percent = 100 * (df_test.isnull().sum() / df_test.isnull().count()).sort_values(ascending=False)\n",
    "missing_df = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Object features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_object = [col for col in df_train.columns if df_train[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ],
      "text/plain": [
       "['Id', 'idhogar', 'dependency', 'edjefe', 'edjefa']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dependecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dependency'] = np.sqrt(df_train['SQBdependency'])\n",
    "df_test['dependency'] = np.sqrt(df_test['SQBdependency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['dependency'] = df_train['dependency'].replace({np.inf: 0})\n",
    "# df_test['dependency'] = df_test['dependency'].replace({np.inf: 0})\n",
    "\n",
    "# def replace_dependency(x):\n",
    "#     if x == 'yes':\n",
    "#         return 10\n",
    "#     elif x == 'no':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return x\n",
    "\n",
    "# df_train['dependency'] = df_train['dependency'].apply(replace_dependency).astype(float)\n",
    "# df_test['dependency'] = df_test['dependency'].apply(replace_dependency).astype(float)\n",
    "\n",
    "# - As you can see, setting yes -> 10 and no -> 0 is good choice.\n",
    "# - At first, fill inf value with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### edjefe\n",
    "- edjefe, years of education of male head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- replace yes -> 1 and no -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefe(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_train['edjefe'] = df_train['edjefe'].apply(replace_edjefe).astype(float)\n",
    "df_test['edjefe'] = df_test['edjefe'].apply(replace_edjefe).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### edjefa\n",
    "- edjefa, years of education of female head of household, based on the interaction of escolari (years of education), head of household and gender, yes=1 and no=0\n",
    "- replace yes -> 1 and no -> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_edjefa(x):\n",
    "    if x == 'yes':\n",
    "        return 1\n",
    "    elif x == 'no':\n",
    "        return 0\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "df_train['edjefa'] = df_train['edjefa'].apply(replace_edjefa).astype(float)\n",
    "df_test['edjefa'] = df_test['edjefa'].apply(replace_edjefa).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['edjef'] = np.max(df_train[['edjefa','edjefe']], axis=1)\n",
    "df_test['edjef'] = np.max(df_test[['edjefa','edjefe']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### roof and electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['roof_waste_material'] = np.nan\n",
    "df_test['roof_waste_material'] = np.nan\n",
    "df_train['electricity_other'] = np.nan\n",
    "df_test['electricity_other'] = np.nan\n",
    "\n",
    "def fill_roof_exception(x):\n",
    "    if (x['techozinc'] == 0) and (x['techoentrepiso'] == 0) and (x['techocane'] == 0) and (x['techootro'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def fill_no_electricity(x):\n",
    "    if (x['public'] == 0) and (x['planpri'] == 0) and (x['noelec'] == 0) and (x['coopele'] == 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_train['roof_waste_material'] = df_train.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "df_test['roof_waste_material'] = df_test.apply(lambda x : fill_roof_exception(x),axis=1)\n",
    "df_train['electricity_other'] = df_train.apply(lambda x : fill_no_electricity(x),axis=1)\n",
    "df_test['electricity_other'] = df_test.apply(lambda x : fill_no_electricity(x),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Extract cat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in df_train.columns if df_train[col].value_counts().shape[0] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Make new features using continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = [col for col in df_train.columns if col not in binary_cat_features]\n",
    "continuous_features = [col for col in continuous_features if col not in features_object]\n",
    "continuous_features = [col for col in continuous_features if col not in ['Id', 'Target', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 continuous features\n",
      "v2a1: [' Monthly rent payment']\n",
      "rooms: ['  number of all rooms in the house']\n",
      "v18q1: [' number of tablets household owns']\n",
      "r4h1: [' Males younger than 12 years of age']\n",
      "r4h2: [' Males 12 years of age and older']\n",
      "r4h3: [' Total males in the household']\n",
      "r4m1: [' Females younger than 12 years of age']\n",
      "r4m2: [' Females 12 years of age and older']\n",
      "r4m3: [' Total females in the household']\n",
      "r4t1: [' persons younger than 12 years of age']\n",
      "r4t2: [' persons 12 years of age and older']\n",
      "r4t3: [' Total persons in the household']\n",
      "tamhog: [' size of the household']\n",
      "tamviv: [' number of persons living in the household']\n",
      "escolari: [' years of schooling']\n",
      "rez_esc: [' Years behind in school']\n",
      "hhsize: [' household size']\n",
      "elimbasu5: [' =1 if rubbish disposal mainly by throwing in river,   creek or sea']\n",
      "hogar_nin: [' Number of children 0 to 19 in household']\n",
      "hogar_adul: [' Number of adults in household']\n",
      "hogar_mayor: [' # of individuals 65+ in the household']\n",
      "hogar_total: [' # of total individuals in the household']\n",
      "meaneduc: ['average years of education for adults (18+)']\n",
      "bedrooms: [' number of bedrooms']\n",
      "overcrowding: [' # persons per room']\n",
      "qmobilephone: [' # of mobile phones']\n",
      "age: [' Age in years']\n",
      "SQBescolari: [' escolari squared']\n",
      "SQBage: [' age squared']\n",
      "SQBhogar_total: [' hogar_total squared']\n",
      "SQBedjefe: [' edjefe squared']\n",
      "SQBhogar_nin: [' hogar_nin squared']\n",
      "SQBovercrowding: [' overcrowding squared']\n",
      "SQBdependency: [' dependency squared']\n",
      "SQBmeaned: [' meaned squared']\n",
      "agesq: [' Age squared']\n",
      "edjef: []\n"
     ]
    }
   ],
   "source": [
    "print('There are {} continuous features'.format(len(continuous_features)))\n",
    "for col in continuous_features:\n",
    "    print('{}: {}'.format(col, description.loc[description['varname'] == col, 'description'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0     2792\n",
       "11.0    1150\n",
       "9.0      723\n",
       "8.0      474\n",
       "15.0     473\n",
       "3.0      459\n",
       "0.0      435\n",
       "7.0      413\n",
       "4.0      400\n",
       "5.0      398\n",
       "14.0     328\n",
       "17.0     278\n",
       "2.0      278\n",
       "16.0     247\n",
       "10.0     207\n",
       "12.0     185\n",
       "13.0     155\n",
       "1.0       65\n",
       "21.0      48\n",
       "18.0      22\n",
       "19.0      18\n",
       "20.0       9\n",
       "Name: edjef, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['edjef'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hhsize : household size\n",
    "- tamhog : size of the household\n",
    "    \n",
    "=> 같음 하나는 제거하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop('tamhog', axis=1, inplace=True)\n",
    "df_test.drop('tamhog', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family features\n",
    "hogar_nin, hogar_adul, hogar_mayor, hogar_total, r4h1, r4h2, r4h3, r4m1, r4m2, r4m3, r4t1, r4t2, r4t3, tmbhog, tamvid, rez_esc, escolari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['adult'] = df_train['hogar_adul'] - df_train['hogar_mayor']\n",
    "df_train['dependency_count'] = df_train['hogar_nin'] + df_train['hogar_mayor']\n",
    "df_train['dependency'] = df_train['dependency_count'] / df_train['adult']\n",
    "df_train['child_percent'] = df_train['hogar_nin'] / df_train['hogar_total']\n",
    "df_train['elder_percent'] = df_train['hogar_mayor'] / df_train['hogar_total']\n",
    "df_train['adult_percent'] = df_train['hogar_adul'] / df_train['hogar_total']\n",
    "df_train['males_younger_12_years_percent'] = df_train['r4h1'] / df_train['hogar_total']\n",
    "df_train['males_older_12_years_percent'] = df_train['r4h2'] / df_train['hogar_total']\n",
    "df_train['males_percent'] = df_train['r4h3'] / df_train['hogar_total']\n",
    "df_train['females_younger_12_years_percent'] = df_train['r4m1'] / df_train['hogar_total']\n",
    "df_train['females_older_12_years_percent'] = df_train['r4m2'] / df_train['hogar_total']\n",
    "df_train['females_percent'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_percent'] = df_train['r4t1'] / df_train['hogar_total']\n",
    "df_train['persons_older_12_years_percent'] = df_train['r4t2'] / df_train['hogar_total']\n",
    "df_train['persons_percent'] = df_train['r4t3'] / df_train['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['adult'] = df_test['hogar_adul'] - df_test['hogar_mayor']\n",
    "df_test['dependency_count'] = df_test['hogar_nin'] + df_test['hogar_mayor']\n",
    "df_test['dependency'] = df_test['dependency_count'] / df_test['adult']\n",
    "df_test['child_percent'] = df_test['hogar_nin'] / df_test['hogar_total']\n",
    "df_test['elder_percent'] = df_test['hogar_mayor'] / df_test['hogar_total']\n",
    "df_test['adult_percent'] = df_test['hogar_adul'] / df_test['hogar_total']\n",
    "df_test['males_younger_12_years_percent'] = df_test['r4h1'] / df_test['hogar_total']\n",
    "df_test['males_older_12_years_percent'] = df_test['r4h2'] / df_test['hogar_total']\n",
    "df_test['males_percent'] = df_test['r4h3'] / df_test['hogar_total']\n",
    "df_test['females_younger_12_years_percent'] = df_test['r4m1'] / df_test['hogar_total']\n",
    "df_test['females_older_12_years_percent'] = df_test['r4m2'] / df_test['hogar_total']\n",
    "df_test['females_percent'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_percent'] = df_test['r4t1'] / df_test['hogar_total']\n",
    "df_test['persons_older_12_years_percent'] = df_test['r4t2'] / df_test['hogar_total']\n",
    "df_test['persons_percent'] = df_test['r4t3'] / df_test['hogar_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['males_younger_12_years_in_household_size'] = df_train['r4h1'] / df_train['hhsize']\n",
    "df_train['males_older_12_years_in_household_size'] = df_train['r4h2'] / df_train['hhsize']\n",
    "df_train['males_in_household_size'] = df_train['r4h3'] / df_train['hhsize']\n",
    "df_train['females_younger_12_years_in_household_size'] = df_train['r4m1'] / df_train['hhsize']\n",
    "df_train['females_older_12_years_in_household_size'] = df_train['r4m2'] / df_train['hhsize']\n",
    "df_train['females_in_household_size'] = df_train['r4m3'] / df_train['hogar_total']\n",
    "df_train['persons_younger_12_years_in_household_size'] = df_train['r4t1'] / df_train['hhsize']\n",
    "df_train['persons_older_12_years_in_household_size'] = df_train['r4t2'] / df_train['hhsize']\n",
    "df_train['persons_in_household_size'] = df_train['r4t3'] / df_train['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['males_younger_12_years_in_household_size'] = df_test['r4h1'] / df_test['hhsize']\n",
    "df_test['males_older_12_years_in_household_size'] = df_test['r4h2'] / df_test['hhsize']\n",
    "df_test['males_in_household_size'] = df_test['r4h3'] / df_test['hhsize']\n",
    "df_test['females_younger_12_years_in_household_size'] = df_test['r4m1'] / df_test['hhsize']\n",
    "df_test['females_older_12_years_in_household_size'] = df_test['r4m2'] / df_test['hhsize']\n",
    "df_test['females_in_household_size'] = df_test['r4m3'] / df_test['hogar_total']\n",
    "df_test['persons_younger_12_years_in_household_size'] = df_test['r4t1'] / df_test['hhsize']\n",
    "df_test['persons_older_12_years_in_household_size'] = df_test['r4t2'] / df_test['hhsize']\n",
    "df_test['persons_in_household_size'] = df_test['r4t3'] / df_test['hhsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['overcrowding_room_and_bedroom'] = (df_train['hacdor'] + df_train['hacapo'])/2\n",
    "df_test['overcrowding_room_and_bedroom'] = (df_test['hacdor'] + df_test['hacapo'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['escolari_age'] = df_train['escolari']/df_train['age']\n",
    "df_test['escolari_age'] = df_test['escolari']/df_test['age']\n",
    "\n",
    "df_train['age_12_19'] = df_train['hogar_nin'] - df_train['r4t1']\n",
    "df_test['age_12_19'] = df_test['hogar_nin'] - df_test['r4t1']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['phones-per-capita'] = df_train['qmobilephone'] / df_train['tamviv']\n",
    "df_train['tablets-per-capita'] = df_train['v18q1'] / df_train['tamviv']\n",
    "df_train['rooms-per-capita'] = df_train['rooms'] / df_train['tamviv']\n",
    "df_train['rent-per-capita'] = df_train['v2a1'] / df_train['tamviv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['phones-per-capita'] = df_test['qmobilephone'] / df_test['tamviv']\n",
    "df_test['tablets-per-capita'] = df_test['v18q1'] / df_test['tamviv']\n",
    "df_test['rooms-per-capita'] = df_test['rooms'] / df_test['tamviv']\n",
    "df_test['rent-per-capita'] = df_test['v2a1'] / df_test['tamviv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that \"Total persons in the household\" != \"# of total individuals in the household\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9509"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train['hogar_total'] == df_train['r4t3']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rent per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_size_features = ['adult', 'hogar_adul', 'hogar_mayor', 'hogar_nin', 'hogar_total', 'r4h1', \n",
    "                        'r4h2', 'r4h3', 'r4m1', 'r4m2', 'r4m3', 'r4t1', 'r4t2', 'r4t3', 'hhsize']\n",
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v2a1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v2a1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v2a1'] / df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Room per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BedRoom per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('bedrooms', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['bedrooms'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['bedrooms'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 220) (23856, 219)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tabulet per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('v18q1', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['v18q1'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['v18q1'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### phone per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('qmobilephone', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['qmobilephone'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['qmobilephone'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rez_esc(Years behind in school) per family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feats = []\n",
    "for col in family_size_features:\n",
    "    new_col_name = 'new_{}_per_{}'.format('rez_esc', col)\n",
    "    new_feats.append(new_col_name)\n",
    "    df_train[new_col_name] = df_train['rez_esc'] / df_train[col]\n",
    "    df_test[new_col_name] = df_test['rez_esc'] / df_test[col]\n",
    "\n",
    "for col in new_feats:\n",
    "    df_train[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_train[col].fillna(0, inplace=True)\n",
    "    \n",
    "    df_test[col].replace([np.inf], np.nan, inplace=True)\n",
    "    df_test[col].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rez_esc_age'] = df_train['rez_esc'] / df_train['age']\n",
    "df_train['rez_esc_escolari'] = df_train['rez_esc'] / df_train['escolari']\n",
    "\n",
    "df_test['rez_esc_age'] = df_test['rez_esc'] / df_test['age']\n",
    "df_test['rez_esc_escolari'] = df_test['rez_esc'] / df_test['escolari']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rich features\n",
    "the more richer, the larger number of phones and tabulet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['tabulet_x_qmobilephone'] = df_train['v18q1'] * df_train['qmobilephone']\n",
    "df_test['tabulet_x_qmobilephone'] = df_test['v18q1'] * df_test['qmobilephone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "# wall and floor\n",
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "# roof and floor\n",
    "for col1 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "    for col2 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['epared1', 'epared2', 'epared3']:\n",
    "    for col2 in ['etecho1', 'etecho2', 'etecho3']:\n",
    "        for col3 in ['eviv1', 'eviv2', 'eviv3']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 322) (23856, 321)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix electricity and energy features -> energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['public', 'planpri', 'noelec', 'coopele']:\n",
    "    for col2 in ['energcocinar1', 'energcocinar2', 'energcocinar3', 'energcocinar4']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix toilet and rubbish disposal features -> other_infra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "    for col2 in ['elimbasu1', 'elimbasu2', 'elimbasu3', 'elimbasu4', 'elimbasu5', 'elimbasu6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix toilet and water provision features -> water features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['abastaguadentro', 'abastaguafuera', 'abastaguano']:\n",
    "    for col2 in ['sanitario1', 'sanitario2', 'sanitario3', 'sanitario5', 'sanitario6']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 383) (23856, 382)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix education and area features -> education_zone_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['area1', 'area2']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix region and education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    for col2 in ['instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 455) (23856, 454)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply television / mobilephone / computer / tabulet / refrigerator -> electornics features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['electronics'] = df_train['computer'] * df_train['mobilephone'] * df_train['television'] * df_train['v18q'] * df_train['refrig']\n",
    "df_test['electronics'] = df_test['computer'] * df_test['mobilephone'] * df_test['television'] * df_test['v18q'] * df_test['refrig']\n",
    "\n",
    "df_train['no_appliances'] = df_train['refrig'] + df_train['computer'] + df_train['television'] + df_train['mobilephone']\n",
    "df_test['no_appliances'] = df_test['refrig'] + df_test['computer'] + df_test['television'] + df_test['mobilephone']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix wall material of roof, floor, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "\n",
    "for col1 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "    for col1 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]\n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "        new_col_name = 'new_{}_x_{}'.format(col1, col2)\n",
    "        df_train[new_col_name] = df_train[col1] * df_train[col2]\n",
    "        df_test[new_col_name] = df_test[col1] * df_test[col2]        \n",
    "        \n",
    "for col1 in ['paredblolad', 'paredzocalo', 'paredpreb', 'pareddes', 'paredmad', 'paredzinc', 'paredfibras', 'paredother']:\n",
    "    for col2 in ['pisomoscer', 'pisocemento', 'pisoother', 'pisonatur', 'pisonotiene', 'pisomadera']:\n",
    "        for col3 in ['techozinc', 'techoentrepiso', 'techocane', 'techootro']:\n",
    "            new_col_name = 'new_{}_x_{}_x_{}'.format(col1, col2, col3)\n",
    "            df_train[new_col_name] = df_train[col1] * df_train[col2] * df_train[col3]\n",
    "            df_test[new_col_name] = df_test[col1] * df_test[col2] * df_train[col3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9557, 733) (23856, 732)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove feature with only one value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elimbasu5\n",
      "new_planpri_x_energcocinar1\n",
      "new_planpri_x_energcocinar2\n",
      "new_planpri_x_energcocinar3\n",
      "new_planpri_x_energcocinar4\n",
      "new_noelec_x_energcocinar2\n",
      "new_sanitario1_x_elimbasu4\n",
      "new_sanitario1_x_elimbasu5\n",
      "new_sanitario1_x_elimbasu6\n",
      "new_sanitario2_x_elimbasu4\n",
      "new_sanitario2_x_elimbasu5\n",
      "new_sanitario2_x_elimbasu6\n",
      "new_sanitario3_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu4\n",
      "new_sanitario5_x_elimbasu5\n",
      "new_sanitario5_x_elimbasu6\n",
      "new_sanitario6_x_elimbasu2\n",
      "new_sanitario6_x_elimbasu4\n",
      "new_sanitario6_x_elimbasu5\n",
      "new_sanitario6_x_elimbasu6\n",
      "new_abastaguafuera_x_sanitario6\n",
      "new_abastaguano_x_sanitario2\n",
      "new_abastaguano_x_sanitario6\n",
      "new_paredblolad_x_pisonatur\n",
      "new_paredblolad_x_pisonotiene\n",
      "new_paredzocalo_x_pisoother\n",
      "new_paredzocalo_x_pisonatur\n",
      "new_paredpreb_x_pisonatur\n",
      "new_pareddes_x_pisoother\n",
      "new_pareddes_x_pisonatur\n",
      "new_paredmad_x_pisoother\n",
      "new_paredmad_x_pisonatur\n",
      "new_paredzinc_x_pisoother\n",
      "new_paredzinc_x_pisonatur\n",
      "new_paredfibras_x_pisoother\n",
      "new_paredfibras_x_pisonatur\n",
      "new_paredfibras_x_pisonotiene\n",
      "new_paredfibras_x_pisomadera\n",
      "new_paredother_x_pisoother\n",
      "new_paredother_x_pisonatur\n",
      "new_paredother_x_pisonotiene\n",
      "new_paredother_x_pisomadera\n",
      "new_techocane_x_pisomadera\n",
      "new_techootro_x_pisomadera\n",
      "new_paredzocalo_x_techoentrepiso\n",
      "new_paredzocalo_x_techocane\n",
      "new_paredzocalo_x_techootro\n",
      "new_paredpreb_x_techootro\n",
      "new_pareddes_x_techoentrepiso\n",
      "new_pareddes_x_techocane\n",
      "new_pareddes_x_techootro\n",
      "new_paredmad_x_techocane\n",
      "new_paredmad_x_techootro\n",
      "new_paredzinc_x_techoentrepiso\n",
      "new_paredzinc_x_techocane\n",
      "new_paredzinc_x_techootro\n",
      "new_paredfibras_x_techoentrepiso\n",
      "new_paredfibras_x_techootro\n",
      "new_paredother_x_techoentrepiso\n",
      "new_paredother_x_techocane\n",
      "new_paredother_x_techootro\n",
      "new_paredblolad_x_pisocemento_x_techocane\n",
      "new_paredblolad_x_pisocemento_x_techootro\n",
      "new_paredblolad_x_pisoother_x_techoentrepiso\n",
      "new_paredblolad_x_pisoother_x_techocane\n",
      "new_paredblolad_x_pisoother_x_techootro\n",
      "new_paredblolad_x_pisonatur_x_techozinc\n",
      "new_paredblolad_x_pisonatur_x_techoentrepiso\n",
      "new_paredblolad_x_pisonatur_x_techocane\n",
      "new_paredblolad_x_pisonatur_x_techootro\n",
      "new_paredblolad_x_pisonotiene_x_techozinc\n",
      "new_paredblolad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredblolad_x_pisonotiene_x_techocane\n",
      "new_paredblolad_x_pisonotiene_x_techootro\n",
      "new_paredblolad_x_pisomadera_x_techocane\n",
      "new_paredblolad_x_pisomadera_x_techootro\n",
      "new_paredzocalo_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomoscer_x_techocane\n",
      "new_paredzocalo_x_pisomoscer_x_techootro\n",
      "new_paredzocalo_x_pisocemento_x_techoentrepiso\n",
      "new_paredzocalo_x_pisocemento_x_techocane\n",
      "new_paredzocalo_x_pisocemento_x_techootro\n",
      "new_paredzocalo_x_pisoother_x_techozinc\n",
      "new_paredzocalo_x_pisoother_x_techoentrepiso\n",
      "new_paredzocalo_x_pisoother_x_techocane\n",
      "new_paredzocalo_x_pisoother_x_techootro\n",
      "new_paredzocalo_x_pisonatur_x_techozinc\n",
      "new_paredzocalo_x_pisonatur_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonatur_x_techocane\n",
      "new_paredzocalo_x_pisonatur_x_techootro\n",
      "new_paredzocalo_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzocalo_x_pisonotiene_x_techocane\n",
      "new_paredzocalo_x_pisonotiene_x_techootro\n",
      "new_paredzocalo_x_pisomadera_x_techoentrepiso\n",
      "new_paredzocalo_x_pisomadera_x_techocane\n",
      "new_paredzocalo_x_pisomadera_x_techootro\n",
      "new_paredpreb_x_pisocemento_x_techoentrepiso\n",
      "new_paredpreb_x_pisocemento_x_techocane\n",
      "new_paredpreb_x_pisocemento_x_techootro\n",
      "new_paredpreb_x_pisoother_x_techoentrepiso\n",
      "new_paredpreb_x_pisoother_x_techocane\n",
      "new_paredpreb_x_pisoother_x_techootro\n",
      "new_paredpreb_x_pisonatur_x_techozinc\n",
      "new_paredpreb_x_pisonatur_x_techoentrepiso\n",
      "new_paredpreb_x_pisonatur_x_techocane\n",
      "new_paredpreb_x_pisonatur_x_techootro\n",
      "new_paredpreb_x_pisonotiene_x_techozinc\n",
      "new_paredpreb_x_pisonotiene_x_techoentrepiso\n",
      "new_paredpreb_x_pisonotiene_x_techocane\n",
      "new_paredpreb_x_pisonotiene_x_techootro\n",
      "new_paredpreb_x_pisomadera_x_techoentrepiso\n",
      "new_paredpreb_x_pisomadera_x_techocane\n",
      "new_paredpreb_x_pisomadera_x_techootro\n",
      "new_pareddes_x_pisomoscer_x_techozinc\n",
      "new_pareddes_x_pisomoscer_x_techoentrepiso\n",
      "new_pareddes_x_pisomoscer_x_techocane\n",
      "new_pareddes_x_pisomoscer_x_techootro\n",
      "new_pareddes_x_pisocemento_x_techoentrepiso\n",
      "new_pareddes_x_pisocemento_x_techocane\n",
      "new_pareddes_x_pisocemento_x_techootro\n",
      "new_pareddes_x_pisoother_x_techozinc\n",
      "new_pareddes_x_pisoother_x_techoentrepiso\n",
      "new_pareddes_x_pisoother_x_techocane\n",
      "new_pareddes_x_pisoother_x_techootro\n",
      "new_pareddes_x_pisonatur_x_techozinc\n",
      "new_pareddes_x_pisonatur_x_techoentrepiso\n",
      "new_pareddes_x_pisonatur_x_techocane\n",
      "new_pareddes_x_pisonatur_x_techootro\n",
      "new_pareddes_x_pisonotiene_x_techoentrepiso\n",
      "new_pareddes_x_pisonotiene_x_techocane\n",
      "new_pareddes_x_pisonotiene_x_techootro\n",
      "new_pareddes_x_pisomadera_x_techozinc\n",
      "new_pareddes_x_pisomadera_x_techoentrepiso\n",
      "new_pareddes_x_pisomadera_x_techocane\n",
      "new_pareddes_x_pisomadera_x_techootro\n",
      "new_paredmad_x_pisomoscer_x_techocane\n",
      "new_paredmad_x_pisomoscer_x_techootro\n",
      "new_paredmad_x_pisocemento_x_techoentrepiso\n",
      "new_paredmad_x_pisocemento_x_techocane\n",
      "new_paredmad_x_pisocemento_x_techootro\n",
      "new_paredmad_x_pisoother_x_techozinc\n",
      "new_paredmad_x_pisoother_x_techoentrepiso\n",
      "new_paredmad_x_pisoother_x_techocane\n",
      "new_paredmad_x_pisoother_x_techootro\n",
      "new_paredmad_x_pisonatur_x_techozinc\n",
      "new_paredmad_x_pisonatur_x_techoentrepiso\n",
      "new_paredmad_x_pisonatur_x_techocane\n",
      "new_paredmad_x_pisonatur_x_techootro\n",
      "new_paredmad_x_pisonotiene_x_techoentrepiso\n",
      "new_paredmad_x_pisonotiene_x_techocane\n",
      "new_paredmad_x_pisonotiene_x_techootro\n",
      "new_paredmad_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techoentrepiso\n",
      "new_paredzinc_x_pisomoscer_x_techocane\n",
      "new_paredzinc_x_pisomoscer_x_techootro\n",
      "new_paredzinc_x_pisocemento_x_techoentrepiso\n",
      "new_paredzinc_x_pisocemento_x_techocane\n",
      "new_paredzinc_x_pisocemento_x_techootro\n",
      "new_paredzinc_x_pisoother_x_techozinc\n",
      "new_paredzinc_x_pisoother_x_techoentrepiso\n",
      "new_paredzinc_x_pisoother_x_techocane\n",
      "new_paredzinc_x_pisoother_x_techootro\n",
      "new_paredzinc_x_pisonatur_x_techozinc\n",
      "new_paredzinc_x_pisonatur_x_techoentrepiso\n",
      "new_paredzinc_x_pisonatur_x_techocane\n",
      "new_paredzinc_x_pisonatur_x_techootro\n",
      "new_paredzinc_x_pisonotiene_x_techoentrepiso\n",
      "new_paredzinc_x_pisonotiene_x_techocane\n",
      "new_paredzinc_x_pisonotiene_x_techootro\n",
      "new_paredzinc_x_pisomadera_x_techoentrepiso\n",
      "new_paredzinc_x_pisomadera_x_techocane\n",
      "new_paredzinc_x_pisomadera_x_techootro\n",
      "new_paredfibras_x_pisomoscer_x_techoentrepiso\n",
      "new_paredfibras_x_pisomoscer_x_techocane\n",
      "new_paredfibras_x_pisomoscer_x_techootro\n",
      "new_paredfibras_x_pisocemento_x_techoentrepiso\n",
      "new_paredfibras_x_pisocemento_x_techocane\n",
      "new_paredfibras_x_pisocemento_x_techootro\n",
      "new_paredfibras_x_pisoother_x_techozinc\n",
      "new_paredfibras_x_pisoother_x_techoentrepiso\n",
      "new_paredfibras_x_pisoother_x_techocane\n",
      "new_paredfibras_x_pisoother_x_techootro\n",
      "new_paredfibras_x_pisonatur_x_techozinc\n",
      "new_paredfibras_x_pisonatur_x_techoentrepiso\n",
      "new_paredfibras_x_pisonatur_x_techocane\n",
      "new_paredfibras_x_pisonatur_x_techootro\n",
      "new_paredfibras_x_pisonotiene_x_techozinc\n",
      "new_paredfibras_x_pisonotiene_x_techoentrepiso\n",
      "new_paredfibras_x_pisonotiene_x_techocane\n",
      "new_paredfibras_x_pisonotiene_x_techootro\n",
      "new_paredfibras_x_pisomadera_x_techozinc\n",
      "new_paredfibras_x_pisomadera_x_techoentrepiso\n",
      "new_paredfibras_x_pisomadera_x_techocane\n",
      "new_paredfibras_x_pisomadera_x_techootro\n",
      "new_paredother_x_pisomoscer_x_techozinc\n",
      "new_paredother_x_pisomoscer_x_techoentrepiso\n",
      "new_paredother_x_pisomoscer_x_techocane\n",
      "new_paredother_x_pisomoscer_x_techootro\n",
      "new_paredother_x_pisocemento_x_techoentrepiso\n",
      "new_paredother_x_pisocemento_x_techocane\n",
      "new_paredother_x_pisocemento_x_techootro\n",
      "new_paredother_x_pisoother_x_techozinc\n",
      "new_paredother_x_pisoother_x_techoentrepiso\n",
      "new_paredother_x_pisoother_x_techocane\n",
      "new_paredother_x_pisoother_x_techootro\n",
      "new_paredother_x_pisonatur_x_techozinc\n",
      "new_paredother_x_pisonatur_x_techoentrepiso\n",
      "new_paredother_x_pisonatur_x_techocane\n",
      "new_paredother_x_pisonatur_x_techootro\n",
      "new_paredother_x_pisonotiene_x_techozinc\n",
      "new_paredother_x_pisonotiene_x_techoentrepiso\n",
      "new_paredother_x_pisonotiene_x_techocane\n",
      "new_paredother_x_pisonotiene_x_techootro\n",
      "new_paredother_x_pisomadera_x_techozinc\n",
      "new_paredother_x_pisomadera_x_techoentrepiso\n",
      "new_paredother_x_pisomadera_x_techocane\n",
      "new_paredother_x_pisomadera_x_techootro\n"
     ]
    }
   ],
   "source": [
    "cols_with_only_one_value = []\n",
    "for col in df_train.columns:\n",
    "    if col == 'Target':\n",
    "        continue\n",
    "    if df_train[col].value_counts().shape[0] == 1 or df_test[col].value_counts().shape[0] == 1:\n",
    "        print(col)\n",
    "        cols_with_only_one_value.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(cols_with_only_one_value, axis=1, inplace=True)\n",
    "df_test.drop(cols_with_only_one_value, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether both train and test have same features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_train = np.array(sorted([col for col in df_train.columns if col != 'Target']))\n",
    "cols_test = np.array(sorted(df_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cols_train == cols_test).sum() == len(cols_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) aggregation features\n",
    "let's aggregate based on 'idhogar' values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregation for family features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_min(x):\n",
    "    return x.max() - x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:37<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 105 features\n",
      "new aggregate test set has 7352 rows, and 105 features\n"
     ]
    }
   ],
   "source": [
    "agg_train = pd.DataFrame()\n",
    "agg_test = pd.DataFrame()\n",
    "\n",
    "for item in tqdm(family_size_features):\n",
    "    for i, function in enumerate(['mean','std','min','max','sum', 'count', max_min]):\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:05<00:00,  8.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 199 features\n",
      "new aggregate test set has 7352 rows, and 199 features\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "\n",
    "\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['count', 'sum']:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        new_col = item + '_new1_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:17<00:00,  1.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new aggregate train set has 2988 rows, and 208 features\n",
      "new aggregate test set has 7352 rows, and 208 features\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['escolari', 'age', 'escolari_age', 'dependency', 'bedrooms', 'overcrowding', 'rooms', 'qmobilephone', 'v18q1']\n",
    "\n",
    "for item in tqdm(aggr_list):\n",
    "    for function in ['mean','std','min','max','sum', 'count', max_min]:\n",
    "        group_train = df_train[item].groupby(df_train['idhogar']).agg(function)\n",
    "        group_test = df_test[item].groupby(df_test['idhogar']).agg(function)\n",
    "        if i == 6:\n",
    "            new_col = item + '_new2_' + 'max_min'\n",
    "        else:\n",
    "            new_col = item + '_new2_' + function\n",
    "        agg_train[new_col] = group_train\n",
    "        agg_test[new_col] = group_test\n",
    "\n",
    "print('new aggregate train set has {} rows, and {} features'.format(agg_train.shape[0], agg_train.shape[1]))\n",
    "print('new aggregate test set has {} rows, and {} features'.format(agg_test.shape[0], agg_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 724) test shape: (23856, 723)\n"
     ]
    }
   ],
   "source": [
    "agg_test = agg_test.reset_index()\n",
    "agg_train = agg_train.reset_index()\n",
    "\n",
    "train_agg = pd.merge(df_train, agg_train, on='idhogar')\n",
    "test = pd.merge(df_test, agg_test, on='idhogar')\n",
    "\n",
    "#fill all na as 0\n",
    "train_agg.fillna(value=0, inplace=True)\n",
    "test.fillna(value=0, inplace=True)\n",
    "\n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1006) test shape: (23856, 1005)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new3_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 1288) test shape: (23856, 1287)\n"
     ]
    }
   ],
   "source": [
    "aggr_list = ['rez_esc', 'dis', 'male', 'female', \n",
    "                  'estadocivil1', 'estadocivil2', 'estadocivil3', 'estadocivil4', 'estadocivil5', 'estadocivil6', 'estadocivil7', \n",
    "                  'parentesco2', 'parentesco3', 'parentesco4', 'parentesco5', 'parentesco6', 'parentesco7', 'parentesco8', 'parentesco9', 'parentesco10', \n",
    "                  'parentesco11', 'parentesco12',\n",
    "                  'instlevel1', 'instlevel2', 'instlevel3', 'instlevel4', 'instlevel5', 'instlevel6', 'instlevel7', 'instlevel8', 'instlevel9',\n",
    "                 'epared1', 'epared2', 'epared3', 'etecho1', 'etecho2', 'etecho3', 'eviv1', 'eviv2', 'eviv3', 'refrig', 'television', 'mobilephone',\n",
    "            'area1', 'area2', 'v18q', 'edjef']\n",
    "    \n",
    "for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "    group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_train.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_train][2:]\n",
    "\n",
    "    group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).sum().reset_index()\n",
    "    group_test.columns = [lugar, 'idhogar'] + ['new4_{}_idhogar_{}'.format(lugar, col) for col in group_test][2:]\n",
    "\n",
    "    train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "    test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "    \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [07:34<00:00, 64.91s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (9557, 3262) test shape: (23856, 3261)\n"
     ]
    }
   ],
   "source": [
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "for function in tqdm(['mean','std','min','max','sum', 'count', max_min]):\n",
    "    for lugar in ['lugar1', 'lugar2', 'lugar3', 'lugar4', 'lugar5', 'lugar6']:\n",
    "        group_train = df_train[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_train.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_train][2:]\n",
    "\n",
    "        group_test = df_test[[lugar, 'idhogar'] + aggr_list].groupby([lugar, 'idhogar']).agg(function).reset_index()\n",
    "        group_test.columns = [lugar, 'idhogar'] + ['new5_{}_idhogar_{}_{}'.format(lugar, col, function) for col in group_test][2:]\n",
    "\n",
    "        train_agg = pd.merge(train_agg, group_train, on=[lugar, 'idhogar'])\n",
    "        test = pd.merge(test, group_test, on=[lugar, 'idhogar'])\n",
    "        \n",
    "print('train shape:', train_agg.shape, 'test shape:', test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 데이터만 scoring에 사용 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_agg.query('parentesco1==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['dependency'].replace(np.inf, 0, inplace=True)\n",
    "test['dependency'].replace(np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['Id']]\n",
    "\n",
    "#Remove useless feature to reduce dimension\n",
    "train.drop(columns=['idhogar','Id', 'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "test.drop(columns=['idhogar','Id',  'agesq', 'hogar_adul', 'SQBescolari', 'SQBage', 'SQBhogar_total', 'SQBedjefe', 'SQBhogar_nin', 'SQBovercrowding', 'SQBdependency', 'SQBmeaned'], inplace=True)\n",
    "\n",
    "correlation = train.corr()\n",
    "correlation = correlation['Target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_data size (2973, 3250) (23856, 3249)\n"
     ]
    }
   ],
   "source": [
    "print('final_data size', train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 positive feature: \n",
      "Target                                1.000000\n",
      "new5_lugar5_idhogar_edjef_max         0.334254\n",
      "new5_lugar1_idhogar_edjef_max         0.334254\n",
      "new5_lugar6_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_max         0.334254\n",
      "new5_lugar4_idhogar_edjef_max         0.334254\n",
      "new5_lugar3_idhogar_edjef_max         0.334254\n",
      "new5_lugar2_idhogar_edjef_mean        0.333873\n",
      "new5_lugar4_idhogar_edjef_mean        0.333873\n",
      "new5_lugar5_idhogar_edjef_mean        0.333873\n",
      "new5_lugar3_idhogar_edjef_mean        0.333873\n",
      "new5_lugar1_idhogar_edjef_mean        0.333873\n",
      "new5_lugar6_idhogar_edjef_mean        0.333873\n",
      "new5_lugar2_idhogar_edjef_min         0.333791\n",
      "edjef                                 0.333791\n",
      "new5_lugar5_idhogar_edjef_min         0.333791\n",
      "new5_lugar6_idhogar_edjef_min         0.333791\n",
      "new5_lugar1_idhogar_edjef_min         0.333791\n",
      "new5_lugar4_idhogar_edjef_min         0.333791\n",
      "new5_lugar3_idhogar_edjef_min         0.333791\n",
      "escolari                              0.333791\n",
      "meaneduc                              0.331489\n",
      "new5_lugar1_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar2_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar5_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar3_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar4_idhogar_instlevel8_max    0.317815\n",
      "new5_lugar6_idhogar_instlevel8_max    0.317815\n",
      "phones-per-capita                     0.299026\n",
      "new5_lugar5_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar3_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar1_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar2_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar6_idhogar_instlevel8_std    0.298251\n",
      "new5_lugar4_idhogar_instlevel8_std    0.298251\n",
      "new_epared3_x_eviv3                   0.298196\n",
      "cielorazo                             0.295249\n",
      "new4_lugar5_idhogar_instlevel8        0.294277\n",
      "new5_lugar5_idhogar_instlevel8_sum    0.294277\n",
      "new5_lugar1_idhogar_instlevel8_sum    0.294277\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 positive feature: \\n{correlation.head(40)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 20 negative feature: \n",
      "new5_lugar5_idhogar_television_<function max_min at 0x000001AF1F5699D8>    NaN\n",
      "new5_lugar5_idhogar_mobilephone_<function max_min at 0x000001AF1F5699D8>   NaN\n",
      "new5_lugar5_idhogar_area1_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar5_idhogar_area2_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar5_idhogar_v18q_<function max_min at 0x000001AF1F5699D8>          NaN\n",
      "new5_lugar6_idhogar_epared1_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_epared2_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_epared3_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_etecho1_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_etecho2_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_etecho3_<function max_min at 0x000001AF1F5699D8>       NaN\n",
      "new5_lugar6_idhogar_eviv1_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar6_idhogar_eviv2_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar6_idhogar_eviv3_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar6_idhogar_refrig_<function max_min at 0x000001AF1F5699D8>        NaN\n",
      "new5_lugar6_idhogar_television_<function max_min at 0x000001AF1F5699D8>    NaN\n",
      "new5_lugar6_idhogar_mobilephone_<function max_min at 0x000001AF1F5699D8>   NaN\n",
      "new5_lugar6_idhogar_area1_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar6_idhogar_area2_<function max_min at 0x000001AF1F5699D8>         NaN\n",
      "new5_lugar6_idhogar_v18q_<function max_min at 0x000001AF1F5699D8>          NaN\n",
      "Name: Target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'The most 20 negative feature: \\n{correlation.tail(20)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Feature selection using shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cat_features = [col for col in train.columns if train[col].value_counts().shape[0] == 2]\n",
    "object_features = ['edjefe', 'edjefa']\n",
    "\n",
    "categorical_feats = binary_cat_features + object_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_macroF1_lgb(truth, predictions):  \n",
    "    # https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.reshape(len(np.unique(truth)),-1).argmax(axis=0)\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', f1, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Target']\n",
    "train.drop(columns=['Target'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_execution_time(start):\n",
    "    end = time.time()\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print('*'*20, \"Execution ended in {:0>2}h {:0>2}m {:05.2f}s\".format(int(hours),int(minutes),seconds), '*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_good_features_using_shap_LGB(params, SEED):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 5\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = train.iloc[train_index], train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb, categorical_feature=categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        print_execution_time(start)\n",
    "\n",
    "    feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "#     feat_importance_df_shap['shap_cumsum'] = feat_importance_df_shap['shap_values'].cumsum() / feat_importance_df_shap['shap_values'].sum()\n",
    "#     good_features = feat_importance_df_shap.loc[feat_importance_df_shap['shap_cumsum'] < 0.999].feature\n",
    "    return feat_importance_df_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 1 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.767933\ttraining's macroF1: 0.69325\tvalid_1's multi_logloss: 1.04467\tvalid_1's macroF1: 0.398167\n",
      "[1000]\ttraining's multi_logloss: 0.607012\ttraining's macroF1: 0.764784\tvalid_1's multi_logloss: 1.03636\tvalid_1's macroF1: 0.39517\n",
      "[1500]\ttraining's multi_logloss: 0.515114\ttraining's macroF1: 0.808828\tvalid_1's multi_logloss: 1.03318\tvalid_1's macroF1: 0.414947\n",
      "[2000]\ttraining's multi_logloss: 0.456736\ttraining's macroF1: 0.832886\tvalid_1's multi_logloss: 1.03487\tvalid_1's macroF1: 0.421428\n",
      "Early stopping, best iteration is:\n",
      "[1716]\ttraining's multi_logloss: 0.486989\ttraining's macroF1: 0.824065\tvalid_1's multi_logloss: 1.03251\tvalid_1's macroF1: 0.424506\n",
      "******************** Execution ended in 00h 02m 47.32s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.773343\ttraining's macroF1: 0.695445\tvalid_1's multi_logloss: 1.01465\tvalid_1's macroF1: 0.410158\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's multi_logloss: 1.23003\ttraining's macroF1: 0.49873\tvalid_1's multi_logloss: 1.21724\tvalid_1's macroF1: 0.430057\n",
      "******************** Execution ended in 00h 00m 40.40s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.773518\ttraining's macroF1: 0.693987\tvalid_1's multi_logloss: 1.03709\tvalid_1's macroF1: 0.409976\n",
      "Early stopping, best iteration is:\n",
      "[455]\ttraining's multi_logloss: 0.794754\ttraining's macroF1: 0.683445\tvalid_1's multi_logloss: 1.04015\tvalid_1's macroF1: 0.414625\n",
      "******************** Execution ended in 00h 01m 08.36s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.771543\ttraining's macroF1: 0.688141\tvalid_1's multi_logloss: 1.04709\tvalid_1's macroF1: 0.400152\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's multi_logloss: 1.02417\ttraining's macroF1: 0.591257\tvalid_1's multi_logloss: 1.08762\tvalid_1's macroF1: 0.411344\n",
      "******************** Execution ended in 00h 00m 48.73s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.76961\ttraining's macroF1: 0.683015\tvalid_1's multi_logloss: 1.00215\tvalid_1's macroF1: 0.419099\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's multi_logloss: 1.08984\ttraining's macroF1: 0.553768\tvalid_1's multi_logloss: 1.10313\tvalid_1's macroF1: 0.434384\n",
      "******************** Execution ended in 00h 00m 45.22s ********************\n",
      "######################################## 2 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.22688\ttraining's macroF1: 0.495856\tvalid_1's multi_logloss: 1.21348\tvalid_1's macroF1: 0.408067\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's multi_logloss: 1.38584\ttraining's macroF1: 0.423294\tvalid_1's multi_logloss: 1.38568\tvalid_1's macroF1: 0.425606\n",
      "******************** Execution ended in 00h 00m 33.83s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23169\ttraining's macroF1: 0.505015\tvalid_1's multi_logloss: 1.19904\tvalid_1's macroF1: 0.395241\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's multi_logloss: 1.34825\ttraining's macroF1: 0.475977\tvalid_1's multi_logloss: 1.33643\tvalid_1's macroF1: 0.412773\n",
      "******************** Execution ended in 00h 01m 31.84s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.22578\ttraining's macroF1: 0.493463\tvalid_1's multi_logloss: 1.20929\tvalid_1's macroF1: 0.394162\n",
      "[1000]\ttraining's multi_logloss: 1.13295\ttraining's macroF1: 0.517332\tvalid_1's multi_logloss: 1.13229\tvalid_1's macroF1: 0.407007\n",
      "[1500]\ttraining's multi_logloss: 1.07094\ttraining's macroF1: 0.537509\tvalid_1's multi_logloss: 1.09504\tvalid_1's macroF1: 0.417418\n",
      "Early stopping, best iteration is:\n",
      "[1304]\ttraining's multi_logloss: 1.0926\ttraining's macroF1: 0.529443\tvalid_1's multi_logloss: 1.10667\tvalid_1's macroF1: 0.420029\n",
      "******************** Execution ended in 00h 02m 16.25s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.22763\ttraining's macroF1: 0.50205\tvalid_1's multi_logloss: 1.20928\tvalid_1's macroF1: 0.368072\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's multi_logloss: 1.37724\ttraining's macroF1: 0.474492\tvalid_1's multi_logloss: 1.37471\tvalid_1's macroF1: 0.385196\n",
      "******************** Execution ended in 00h 00m 38.15s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23489\ttraining's macroF1: 0.491725\tvalid_1's multi_logloss: 1.18636\tvalid_1's macroF1: 0.400467\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 1.37412\ttraining's macroF1: 0.472927\tvalid_1's multi_logloss: 1.3682\tvalid_1's macroF1: 0.409073\n",
      "******************** Execution ended in 00h 00m 44.99s ********************\n",
      "######################################## 3 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.925815\ttraining's macroF1: 0.624826\tvalid_1's multi_logloss: 1.08512\tvalid_1's macroF1: 0.38605\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's multi_logloss: 1.22143\ttraining's macroF1: 0.530789\tvalid_1's multi_logloss: 1.23282\tvalid_1's macroF1: 0.39411\n",
      "******************** Execution ended in 00h 01m 10.59s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.946021\ttraining's macroF1: 0.626522\tvalid_1's multi_logloss: 1.02627\tvalid_1's macroF1: 0.408256\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's multi_logloss: 1.33393\ttraining's macroF1: 0.506832\tvalid_1's multi_logloss: 1.3214\tvalid_1's macroF1: 0.423836\n",
      "******************** Execution ended in 00h 00m 54.70s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.951205\ttraining's macroF1: 0.621551\tvalid_1's multi_logloss: 1.04552\tvalid_1's macroF1: 0.412374\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's multi_logloss: 1.26256\ttraining's macroF1: 0.533544\tvalid_1's multi_logloss: 1.2493\tvalid_1's macroF1: 0.431605\n",
      "******************** Execution ended in 00h 01m 00.17s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.955614\ttraining's macroF1: 0.618992\tvalid_1's multi_logloss: 1.03307\tvalid_1's macroF1: 0.410453\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 1.34255\ttraining's macroF1: 0.512911\tvalid_1's multi_logloss: 1.3358\tvalid_1's macroF1: 0.441621\n",
      "******************** Execution ended in 00h 00m 56.47s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.957289\ttraining's macroF1: 0.619622\tvalid_1's multi_logloss: 1.01083\tvalid_1's macroF1: 0.43506\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's multi_logloss: 1.08655\ttraining's macroF1: 0.587066\tvalid_1's multi_logloss: 1.07904\tvalid_1's macroF1: 0.442916\n",
      "******************** Execution ended in 00h 01m 10.73s ********************\n",
      "######################################## 4 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0889\ttraining's macroF1: 0.541148\tvalid_1's multi_logloss: 1.11915\tvalid_1's macroF1: 0.360166\n",
      "[1000]\ttraining's multi_logloss: 0.97914\ttraining's macroF1: 0.574535\tvalid_1's multi_logloss: 1.07832\tvalid_1's macroF1: 0.356821\n",
      "Early stopping, best iteration is:\n",
      "[542]\ttraining's multi_logloss: 1.07653\ttraining's macroF1: 0.540646\tvalid_1's multi_logloss: 1.11229\tvalid_1's macroF1: 0.364742\n",
      "******************** Execution ended in 00h 01m 19.24s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11469\ttraining's macroF1: 0.520999\tvalid_1's multi_logloss: 1.0895\tvalid_1's macroF1: 0.413291\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 1.37253\ttraining's macroF1: 0.442859\tvalid_1's multi_logloss: 1.36778\tvalid_1's macroF1: 0.441729\n",
      "******************** Execution ended in 00h 00m 40.36s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10431\ttraining's macroF1: 0.530336\tvalid_1's multi_logloss: 1.11147\tvalid_1's macroF1: 0.411133\n",
      "[1000]\ttraining's multi_logloss: 0.99591\ttraining's macroF1: 0.571308\tvalid_1's multi_logloss: 1.06866\tvalid_1's macroF1: 0.422746\n",
      "Early stopping, best iteration is:\n",
      "[837]\ttraining's multi_logloss: 1.02393\ttraining's macroF1: 0.560938\tvalid_1's multi_logloss: 1.07655\tvalid_1's macroF1: 0.430598\n",
      "******************** Execution ended in 00h 01m 40.07s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1053\ttraining's macroF1: 0.531746\tvalid_1's multi_logloss: 1.0814\tvalid_1's macroF1: 0.41787\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.38156\ttraining's macroF1: 0.42921\tvalid_1's multi_logloss: 1.37959\tvalid_1's macroF1: 0.431215\n",
      "******************** Execution ended in 00h 00m 39.26s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10688\ttraining's macroF1: 0.546529\tvalid_1's multi_logloss: 1.0979\tvalid_1's macroF1: 0.3981\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's multi_logloss: 1.33948\ttraining's macroF1: 0.447389\tvalid_1's multi_logloss: 1.3256\tvalid_1's macroF1: 0.415653\n",
      "******************** Execution ended in 00h 00m 43.28s ********************\n",
      "######################################## 5 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1441\ttraining's macroF1: 0.495024\tvalid_1's multi_logloss: 1.13314\tvalid_1's macroF1: 0.393195\n",
      "[1000]\ttraining's multi_logloss: 1.0533\ttraining's macroF1: 0.526596\tvalid_1's multi_logloss: 1.08619\tvalid_1's macroF1: 0.401772\n",
      "Early stopping, best iteration is:\n",
      "[799]\ttraining's multi_logloss: 1.0831\ttraining's macroF1: 0.517795\tvalid_1's multi_logloss: 1.09672\tvalid_1's macroF1: 0.414417\n",
      "******************** Execution ended in 00h 01m 11.35s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.15085\ttraining's macroF1: 0.487607\tvalid_1's multi_logloss: 1.09993\tvalid_1's macroF1: 0.406047\n",
      "[1000]\ttraining's multi_logloss: 1.06034\ttraining's macroF1: 0.522438\tvalid_1's multi_logloss: 1.03383\tvalid_1's macroF1: 0.416239\n",
      "Early stopping, best iteration is:\n",
      "[910]\ttraining's multi_logloss: 1.07251\ttraining's macroF1: 0.514741\tvalid_1's multi_logloss: 1.04076\tvalid_1's macroF1: 0.426274\n",
      "******************** Execution ended in 00h 01m 34.64s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1507\ttraining's macroF1: 0.508324\tvalid_1's multi_logloss: 1.13769\tvalid_1's macroF1: 0.377189\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 1.37516\ttraining's macroF1: 0.436983\tvalid_1's multi_logloss: 1.37154\tvalid_1's macroF1: 0.383796\n",
      "******************** Execution ended in 00h 00m 36.35s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.15532\ttraining's macroF1: 0.500536\tvalid_1's multi_logloss: 1.14412\tvalid_1's macroF1: 0.421452\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's multi_logloss: 1.21805\ttraining's macroF1: 0.47406\tvalid_1's multi_logloss: 1.1948\tvalid_1's macroF1: 0.431608\n",
      "******************** Execution ended in 00h 00m 59.09s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.14964\ttraining's macroF1: 0.509745\tvalid_1's multi_logloss: 1.10481\tvalid_1's macroF1: 0.396304\n",
      "Early stopping, best iteration is:\n",
      "[178]\ttraining's multi_logloss: 1.26694\ttraining's macroF1: 0.485275\tvalid_1's multi_logloss: 1.2259\tvalid_1's macroF1: 0.413746\n",
      "******************** Execution ended in 00h 00m 51.07s ********************\n",
      "######################################## 6 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.966318\ttraining's macroF1: 0.573158\tvalid_1's multi_logloss: 1.05303\tvalid_1's macroF1: 0.337659\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's multi_logloss: 1.23184\ttraining's macroF1: 0.487274\tvalid_1's multi_logloss: 1.20331\tvalid_1's macroF1: 0.369936\n",
      "******************** Execution ended in 00h 00m 40.71s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.978369\ttraining's macroF1: 0.553806\tvalid_1's multi_logloss: 1.0017\tvalid_1's macroF1: 0.424911\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's multi_logloss: 1.11406\ttraining's macroF1: 0.506603\tvalid_1's multi_logloss: 1.06615\tvalid_1's macroF1: 0.457095\n",
      "******************** Execution ended in 00h 00m 46.15s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.971304\ttraining's macroF1: 0.570661\tvalid_1's multi_logloss: 1.03617\tvalid_1's macroF1: 0.445178\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's multi_logloss: 0.971596\ttraining's macroF1: 0.570568\tvalid_1's multi_logloss: 1.03623\tvalid_1's macroF1: 0.445178\n",
      "******************** Execution ended in 00h 00m 53.89s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.968128\ttraining's macroF1: 0.569696\tvalid_1's multi_logloss: 1.0573\tvalid_1's macroF1: 0.407231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\ttraining's multi_logloss: 0.8595\ttraining's macroF1: 0.628009\tvalid_1's multi_logloss: 1.04653\tvalid_1's macroF1: 0.393858\n",
      "Early stopping, best iteration is:\n",
      "[530]\ttraining's multi_logloss: 0.9594\ttraining's macroF1: 0.57301\tvalid_1's multi_logloss: 1.0558\tvalid_1's macroF1: 0.411816\n",
      "******************** Execution ended in 00h 00m 56.84s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.975338\ttraining's macroF1: 0.572428\tvalid_1's multi_logloss: 1.09166\tvalid_1's macroF1: 0.418761\n",
      "Early stopping, best iteration is:\n",
      "[346]\ttraining's multi_logloss: 1.03057\ttraining's macroF1: 0.550996\tvalid_1's multi_logloss: 1.09848\tvalid_1's macroF1: 0.43111\n",
      "******************** Execution ended in 00h 00m 47.18s ********************\n",
      "######################################## 7 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.826722\ttraining's macroF1: 0.695719\tvalid_1's multi_logloss: 0.984057\tvalid_1's macroF1: 0.409337\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's multi_logloss: 1.29447\ttraining's macroF1: 0.557102\tvalid_1's multi_logloss: 1.27671\tvalid_1's macroF1: 0.434162\n",
      "******************** Execution ended in 00h 00m 42.26s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.818751\ttraining's macroF1: 0.690392\tvalid_1's multi_logloss: 1.00624\tvalid_1's macroF1: 0.434108\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttraining's multi_logloss: 0.944222\ttraining's macroF1: 0.638174\tvalid_1's multi_logloss: 1.03448\tvalid_1's macroF1: 0.450867\n",
      "******************** Execution ended in 00h 01m 04.06s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.822993\ttraining's macroF1: 0.699738\tvalid_1's multi_logloss: 0.991019\tvalid_1's macroF1: 0.433899\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's multi_logloss: 1.32942\ttraining's macroF1: 0.548407\tvalid_1's multi_logloss: 1.31746\tvalid_1's macroF1: 0.453512\n",
      "******************** Execution ended in 00h 01m 26.95s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.82524\ttraining's macroF1: 0.688403\tvalid_1's multi_logloss: 0.970528\tvalid_1's macroF1: 0.432124\n",
      "[1000]\ttraining's multi_logloss: 0.644804\ttraining's macroF1: 0.767267\tvalid_1's multi_logloss: 0.946397\tvalid_1's macroF1: 0.429026\n",
      "Early stopping, best iteration is:\n",
      "[694]\ttraining's multi_logloss: 0.742072\ttraining's macroF1: 0.732367\tvalid_1's multi_logloss: 0.955948\tvalid_1's macroF1: 0.441796\n",
      "******************** Execution ended in 00h 01m 32.93s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.808667\ttraining's macroF1: 0.698592\tvalid_1's multi_logloss: 1.04601\tvalid_1's macroF1: 0.406629\n",
      "[1000]\ttraining's multi_logloss: 0.630542\ttraining's macroF1: 0.774661\tvalid_1's multi_logloss: 1.03756\tvalid_1's macroF1: 0.403444\n",
      "Early stopping, best iteration is:\n",
      "[589]\ttraining's multi_logloss: 0.768399\ttraining's macroF1: 0.714712\tvalid_1's multi_logloss: 1.04094\tvalid_1's macroF1: 0.412911\n",
      "******************** Execution ended in 00h 01m 26.29s ********************\n",
      "######################################## 8 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03984\ttraining's macroF1: 0.516682\tvalid_1's multi_logloss: 1.10887\tvalid_1's macroF1: 0.390962\n",
      "[1000]\ttraining's multi_logloss: 0.951287\ttraining's macroF1: 0.558711\tvalid_1's multi_logloss: 1.10152\tvalid_1's macroF1: 0.385608\n",
      "[1500]\ttraining's multi_logloss: 0.891457\ttraining's macroF1: 0.597112\tvalid_1's multi_logloss: 1.09975\tvalid_1's macroF1: 0.397381\n",
      "[2000]\ttraining's multi_logloss: 0.845022\ttraining's macroF1: 0.618625\tvalid_1's multi_logloss: 1.09854\tvalid_1's macroF1: 0.391208\n",
      "Early stopping, best iteration is:\n",
      "[1726]\ttraining's multi_logloss: 0.869188\ttraining's macroF1: 0.60712\tvalid_1's multi_logloss: 1.09883\tvalid_1's macroF1: 0.401513\n",
      "******************** Execution ended in 00h 02m 09.48s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05238\ttraining's macroF1: 0.530829\tvalid_1's multi_logloss: 1.07122\tvalid_1's macroF1: 0.390849\n",
      "[1000]\ttraining's multi_logloss: 0.964782\ttraining's macroF1: 0.568394\tvalid_1's multi_logloss: 1.05585\tvalid_1's macroF1: 0.39052\n",
      "[1500]\ttraining's multi_logloss: 0.906231\ttraining's macroF1: 0.602683\tvalid_1's multi_logloss: 1.05188\tvalid_1's macroF1: 0.403647\n",
      "Early stopping, best iteration is:\n",
      "[1324]\ttraining's multi_logloss: 0.924661\ttraining's macroF1: 0.58949\tvalid_1's multi_logloss: 1.05281\tvalid_1's macroF1: 0.413097\n",
      "******************** Execution ended in 00h 02m 04.87s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.04428\ttraining's macroF1: 0.541746\tvalid_1's multi_logloss: 1.08067\tvalid_1's macroF1: 0.406511\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's multi_logloss: 1.12618\ttraining's macroF1: 0.51885\tvalid_1's multi_logloss: 1.11236\tvalid_1's macroF1: 0.413228\n",
      "******************** Execution ended in 00h 00m 53.25s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05359\ttraining's macroF1: 0.51658\tvalid_1's multi_logloss: 1.04984\tvalid_1's macroF1: 0.42287\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's multi_logloss: 1.20818\ttraining's macroF1: 0.476689\tvalid_1's multi_logloss: 1.15455\tvalid_1's macroF1: 0.444977\n",
      "******************** Execution ended in 00h 00m 43.52s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.05372\ttraining's macroF1: 0.518228\tvalid_1's multi_logloss: 1.06292\tvalid_1's macroF1: 0.395232\n",
      "[1000]\ttraining's multi_logloss: 0.963068\ttraining's macroF1: 0.566849\tvalid_1's multi_logloss: 1.04845\tvalid_1's macroF1: 0.399911\n",
      "Early stopping, best iteration is:\n",
      "[659]\ttraining's multi_logloss: 1.0186\ttraining's macroF1: 0.531508\tvalid_1's multi_logloss: 1.05564\tvalid_1's macroF1: 0.410574\n",
      "******************** Execution ended in 00h 01m 17.19s ********************\n",
      "######################################## 9 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16761\ttraining's macroF1: 0.532407\tvalid_1's multi_logloss: 1.15834\tvalid_1's macroF1: 0.393695\n",
      "Early stopping, best iteration is:\n",
      "[313]\ttraining's multi_logloss: 1.22648\ttraining's macroF1: 0.512611\tvalid_1's multi_logloss: 1.20861\tvalid_1's macroF1: 0.409721\n",
      "******************** Execution ended in 00h 00m 51.04s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16858\ttraining's macroF1: 0.518071\tvalid_1's multi_logloss: 1.1445\tvalid_1's macroF1: 0.4098\n",
      "[1000]\ttraining's multi_logloss: 1.06759\ttraining's macroF1: 0.54596\tvalid_1's multi_logloss: 1.07622\tvalid_1's macroF1: 0.417046\n",
      "[1500]\ttraining's multi_logloss: 1.005\ttraining's macroF1: 0.570504\tvalid_1's multi_logloss: 1.052\tvalid_1's macroF1: 0.421975\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's multi_logloss: 1.03298\ttraining's macroF1: 0.556808\tvalid_1's multi_logloss: 1.06119\tvalid_1's macroF1: 0.427566\n",
      "******************** Execution ended in 00h 02m 36.39s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.16274\ttraining's macroF1: 0.52445\tvalid_1's multi_logloss: 1.14683\tvalid_1's macroF1: 0.357564\n",
      "[1000]\ttraining's multi_logloss: 1.06253\ttraining's macroF1: 0.547477\tvalid_1's multi_logloss: 1.07894\tvalid_1's macroF1: 0.361998\n",
      "[1500]\ttraining's multi_logloss: 1.00112\ttraining's macroF1: 0.573287\tvalid_1's multi_logloss: 1.0537\tvalid_1's macroF1: 0.385698\n",
      "[2000]\ttraining's multi_logloss: 0.956142\ttraining's macroF1: 0.593908\tvalid_1's multi_logloss: 1.04347\tvalid_1's macroF1: 0.396535\n",
      "[2500]\ttraining's multi_logloss: 0.919347\ttraining's macroF1: 0.609805\tvalid_1's multi_logloss: 1.03731\tvalid_1's macroF1: 0.404593\n",
      "[3000]\ttraining's multi_logloss: 0.887951\ttraining's macroF1: 0.623489\tvalid_1's multi_logloss: 1.03384\tvalid_1's macroF1: 0.417544\n",
      "Early stopping, best iteration is:\n",
      "[2860]\ttraining's multi_logloss: 0.896367\ttraining's macroF1: 0.618345\tvalid_1's multi_logloss: 1.03498\tvalid_1's macroF1: 0.425212\n",
      "******************** Execution ended in 00h 05m 57.03s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1695\ttraining's macroF1: 0.52111\tvalid_1's multi_logloss: 1.13899\tvalid_1's macroF1: 0.4051\n",
      "Early stopping, best iteration is:\n",
      "[412]\ttraining's multi_logloss: 1.19534\ttraining's macroF1: 0.51563\tvalid_1's multi_logloss: 1.16348\tvalid_1's macroF1: 0.414629\n",
      "******************** Execution ended in 00h 01m 34.35s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17507\ttraining's macroF1: 0.51694\tvalid_1's multi_logloss: 1.12507\tvalid_1's macroF1: 0.437063\n",
      "[1000]\ttraining's multi_logloss: 1.07599\ttraining's macroF1: 0.545876\tvalid_1's multi_logloss: 1.04034\tvalid_1's macroF1: 0.448259\n",
      "Early stopping, best iteration is:\n",
      "[903]\ttraining's multi_logloss: 1.09128\ttraining's macroF1: 0.544011\tvalid_1's multi_logloss: 1.05159\tvalid_1's macroF1: 0.453483\n",
      "******************** Execution ended in 00h 02m 22.87s ********************\n",
      "######################################## 10 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.940907\ttraining's macroF1: 0.624572\tvalid_1's multi_logloss: 1.06621\tvalid_1's macroF1: 0.402339\n",
      "[1000]\ttraining's multi_logloss: 0.792358\ttraining's macroF1: 0.692771\tvalid_1's multi_logloss: 1.04499\tvalid_1's macroF1: 0.418653\n",
      "[1500]\ttraining's multi_logloss: 0.695419\ttraining's macroF1: 0.745637\tvalid_1's multi_logloss: 1.03513\tvalid_1's macroF1: 0.410706\n",
      "Early stopping, best iteration is:\n",
      "[1102]\ttraining's multi_logloss: 0.769605\ttraining's macroF1: 0.704525\tvalid_1's multi_logloss: 1.04212\tvalid_1's macroF1: 0.425851\n",
      "******************** Execution ended in 00h 03m 13.74s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.942151\ttraining's macroF1: 0.609363\tvalid_1's multi_logloss: 1.01015\tvalid_1's macroF1: 0.423817\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttraining's multi_logloss: 1.06205\ttraining's macroF1: 0.576187\tvalid_1's multi_logloss: 1.06638\tvalid_1's macroF1: 0.432868\n",
      "******************** Execution ended in 00h 01m 34.88s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.94406\ttraining's macroF1: 0.634547\tvalid_1's multi_logloss: 1.02895\tvalid_1's macroF1: 0.423657\n",
      "[1000]\ttraining's multi_logloss: 0.795454\ttraining's macroF1: 0.698295\tvalid_1's multi_logloss: 0.999887\tvalid_1's macroF1: 0.434177\n",
      "[1500]\ttraining's multi_logloss: 0.699102\ttraining's macroF1: 0.727894\tvalid_1's multi_logloss: 0.986888\tvalid_1's macroF1: 0.437303\n",
      "[2000]\ttraining's multi_logloss: 0.630014\ttraining's macroF1: 0.757575\tvalid_1's multi_logloss: 0.977913\tvalid_1's macroF1: 0.449357\n",
      "[2500]\ttraining's multi_logloss: 0.576486\ttraining's macroF1: 0.788599\tvalid_1's multi_logloss: 0.972581\tvalid_1's macroF1: 0.450374\n",
      "Early stopping, best iteration is:\n",
      "[2128]\ttraining's multi_logloss: 0.614939\ttraining's macroF1: 0.763072\tvalid_1's multi_logloss: 0.976547\tvalid_1's macroF1: 0.455591\n",
      "******************** Execution ended in 00h 04m 52.27s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.943163\ttraining's macroF1: 0.630781\tvalid_1's multi_logloss: 1.02239\tvalid_1's macroF1: 0.406846\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's multi_logloss: 1.14583\ttraining's macroF1: 0.562198\tvalid_1's multi_logloss: 1.13092\tvalid_1's macroF1: 0.430901\n",
      "******************** Execution ended in 00h 00m 43.48s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.938918\ttraining's macroF1: 0.62694\tvalid_1's multi_logloss: 1.03294\tvalid_1's macroF1: 0.416836\n",
      "[1000]\ttraining's multi_logloss: 0.790443\ttraining's macroF1: 0.692453\tvalid_1's multi_logloss: 1.01097\tvalid_1's macroF1: 0.446053\n",
      "[1500]\ttraining's multi_logloss: 0.694465\ttraining's macroF1: 0.733586\tvalid_1's multi_logloss: 1.00513\tvalid_1's macroF1: 0.431861\n",
      "Early stopping, best iteration is:\n",
      "[1087]\ttraining's multi_logloss: 0.770928\ttraining's macroF1: 0.701123\tvalid_1's multi_logloss: 1.00957\tvalid_1's macroF1: 0.450327\n",
      "******************** Execution ended in 00h 21m 48.29s ********************\n",
      "######################################## 11 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03084\ttraining's macroF1: 0.527847\tvalid_1's multi_logloss: 1.03449\tvalid_1's macroF1: 0.397918\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's multi_logloss: 1.11457\ttraining's macroF1: 0.49799\tvalid_1's multi_logloss: 1.06907\tvalid_1's macroF1: 0.41655\n",
      "******************** Execution ended in 00h 00m 39.10s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02242\ttraining's macroF1: 0.533884\tvalid_1's multi_logloss: 1.06002\tvalid_1's macroF1: 0.403067\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's multi_logloss: 1.38004\ttraining's macroF1: 0.421852\tvalid_1's multi_logloss: 1.37719\tvalid_1's macroF1: 0.413889\n",
      "******************** Execution ended in 00h 00m 26.89s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02737\ttraining's macroF1: 0.540247\tvalid_1's multi_logloss: 1.07274\tvalid_1's macroF1: 0.382346\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's multi_logloss: 1.09184\ttraining's macroF1: 0.512508\tvalid_1's multi_logloss: 1.09576\tvalid_1's macroF1: 0.405981\n",
      "******************** Execution ended in 00h 01m 23.47s ********************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.03296\ttraining's macroF1: 0.529546\tvalid_1's multi_logloss: 1.07173\tvalid_1's macroF1: 0.394307\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.3755\ttraining's macroF1: 0.399976\tvalid_1's multi_logloss: 1.36939\tvalid_1's macroF1: 0.429603\n",
      "******************** Execution ended in 00h 00m 27.13s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.02165\ttraining's macroF1: 0.538264\tvalid_1's multi_logloss: 1.10842\tvalid_1's macroF1: 0.367618\n",
      "[1000]\ttraining's multi_logloss: 0.931549\ttraining's macroF1: 0.581093\tvalid_1's multi_logloss: 1.10658\tvalid_1's macroF1: 0.378772\n",
      "[1500]\ttraining's multi_logloss: 0.8734\ttraining's macroF1: 0.611337\tvalid_1's multi_logloss: 1.10279\tvalid_1's macroF1: 0.389806\n",
      "[2000]\ttraining's multi_logloss: 0.828428\ttraining's macroF1: 0.63064\tvalid_1's multi_logloss: 1.10047\tvalid_1's macroF1: 0.399072\n",
      "Early stopping, best iteration is:\n",
      "[1959]\ttraining's multi_logloss: 0.831785\ttraining's macroF1: 0.635364\tvalid_1's multi_logloss: 1.09849\tvalid_1's macroF1: 0.401871\n",
      "******************** Execution ended in 00h 02m 23.02s ********************\n",
      "######################################## 12 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23505\ttraining's macroF1: 0.575603\tvalid_1's multi_logloss: 1.23673\tvalid_1's macroF1: 0.407021\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's multi_logloss: 1.32194\ttraining's macroF1: 0.568222\tvalid_1's multi_logloss: 1.3184\tvalid_1's macroF1: 0.425656\n",
      "******************** Execution ended in 00h 01m 46.20s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23628\ttraining's macroF1: 0.586623\tvalid_1's multi_logloss: 1.22279\tvalid_1's macroF1: 0.399927\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's multi_logloss: 1.32998\ttraining's macroF1: 0.573373\tvalid_1's multi_logloss: 1.32017\tvalid_1's macroF1: 0.413317\n",
      "******************** Execution ended in 00h 01m 18.42s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23273\ttraining's macroF1: 0.566956\tvalid_1's multi_logloss: 1.23011\tvalid_1's macroF1: 0.384353\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's multi_logloss: 1.3859\ttraining's macroF1: 0.4437\tvalid_1's multi_logloss: 1.38584\tvalid_1's macroF1: 0.402436\n",
      "******************** Execution ended in 00h 00m 57.44s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.24059\ttraining's macroF1: 0.584449\tvalid_1's multi_logloss: 1.23037\tvalid_1's macroF1: 0.421638\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's multi_logloss: 1.36662\ttraining's macroF1: 0.540409\tvalid_1's multi_logloss: 1.36313\tvalid_1's macroF1: 0.436262\n",
      "******************** Execution ended in 00h 00m 53.88s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23539\ttraining's macroF1: 0.561336\tvalid_1's multi_logloss: 1.23691\tvalid_1's macroF1: 0.408964\n",
      "[1000]\ttraining's multi_logloss: 1.13271\ttraining's macroF1: 0.589007\tvalid_1's multi_logloss: 1.15265\tvalid_1's macroF1: 0.435371\n",
      "[1500]\ttraining's multi_logloss: 1.05543\ttraining's macroF1: 0.605033\tvalid_1's multi_logloss: 1.09936\tvalid_1's macroF1: 0.433252\n",
      "[2000]\ttraining's multi_logloss: 0.994676\ttraining's macroF1: 0.632221\tvalid_1's multi_logloss: 1.06506\tvalid_1's macroF1: 0.428095\n",
      "Early stopping, best iteration is:\n",
      "[1532]\ttraining's multi_logloss: 1.05121\ttraining's macroF1: 0.608171\tvalid_1's multi_logloss: 1.09691\tvalid_1's macroF1: 0.440213\n",
      "******************** Execution ended in 00h 03m 58.92s ********************\n",
      "######################################## 13 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.33013\ttraining's macroF1: 0.458103\tvalid_1's multi_logloss: 1.31457\tvalid_1's macroF1: 0.379291\n",
      "[1000]\ttraining's multi_logloss: 1.28424\ttraining's macroF1: 0.469116\tvalid_1's multi_logloss: 1.26134\tvalid_1's macroF1: 0.389114\n",
      "[1500]\ttraining's multi_logloss: 1.24535\ttraining's macroF1: 0.486814\tvalid_1's multi_logloss: 1.21874\tvalid_1's macroF1: 0.400477\n",
      "[2000]\ttraining's multi_logloss: 1.21226\ttraining's macroF1: 0.494839\tvalid_1's multi_logloss: 1.18461\tvalid_1's macroF1: 0.401269\n",
      "[2500]\ttraining's multi_logloss: 1.18363\ttraining's macroF1: 0.506859\tvalid_1's multi_logloss: 1.15701\tvalid_1's macroF1: 0.411073\n",
      "Early stopping, best iteration is:\n",
      "[2392]\ttraining's multi_logloss: 1.18944\ttraining's macroF1: 0.504021\tvalid_1's multi_logloss: 1.1624\tvalid_1's macroF1: 0.417142\n",
      "******************** Execution ended in 00h 03m 56.16s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.33021\ttraining's macroF1: 0.463485\tvalid_1's multi_logloss: 1.31355\tvalid_1's macroF1: 0.371244\n",
      "[1000]\ttraining's multi_logloss: 1.28474\ttraining's macroF1: 0.480266\tvalid_1's multi_logloss: 1.26058\tvalid_1's macroF1: 0.368525\n",
      "Early stopping, best iteration is:\n",
      "[552]\ttraining's multi_logloss: 1.32509\ttraining's macroF1: 0.466921\tvalid_1's multi_logloss: 1.30735\tvalid_1's macroF1: 0.37578\n",
      "******************** Execution ended in 00h 01m 24.06s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32834\ttraining's macroF1: 0.478195\tvalid_1's multi_logloss: 1.31896\tvalid_1's macroF1: 0.407316\n",
      "Early stopping, best iteration is:\n",
      "[447]\ttraining's multi_logloss: 1.33393\ttraining's macroF1: 0.472884\tvalid_1's multi_logloss: 1.32517\tvalid_1's macroF1: 0.412321\n",
      "******************** Execution ended in 00h 01m 38.92s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.32926\ttraining's macroF1: 0.462486\tvalid_1's multi_logloss: 1.31022\tvalid_1's macroF1: 0.386064\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's multi_logloss: 1.38236\ttraining's macroF1: 0.45737\tvalid_1's multi_logloss: 1.38084\tvalid_1's macroF1: 0.414432\n",
      "******************** Execution ended in 00h 00m 41.14s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.3311\ttraining's macroF1: 0.462363\tvalid_1's multi_logloss: 1.31799\tvalid_1's macroF1: 0.350352\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's multi_logloss: 1.38333\ttraining's macroF1: 0.434146\tvalid_1's multi_logloss: 1.3824\tvalid_1's macroF1: 0.387957\n",
      "******************** Execution ended in 00h 00m 45.18s ********************\n",
      "######################################## 14 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.876371\ttraining's macroF1: 0.637625\tvalid_1's multi_logloss: 1.05266\tvalid_1's macroF1: 0.368676\n",
      "[1000]\ttraining's multi_logloss: 0.732069\ttraining's macroF1: 0.703012\tvalid_1's multi_logloss: 1.04595\tvalid_1's macroF1: 0.378734\n",
      "Early stopping, best iteration is:\n",
      "[711]\ttraining's multi_logloss: 0.805799\ttraining's macroF1: 0.676598\tvalid_1's multi_logloss: 1.05002\tvalid_1's macroF1: 0.397696\n",
      "******************** Execution ended in 00h 01m 21.70s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.872225\ttraining's macroF1: 0.630418\tvalid_1's multi_logloss: 1.09646\tvalid_1's macroF1: 0.392762\n",
      "Early stopping, best iteration is:\n",
      "[381]\ttraining's multi_logloss: 0.925217\ttraining's macroF1: 0.602595\tvalid_1's multi_logloss: 1.09825\tvalid_1's macroF1: 0.41067\n",
      "******************** Execution ended in 00h 01m 02.69s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.88719\ttraining's macroF1: 0.625475\tvalid_1's multi_logloss: 0.990429\tvalid_1's macroF1: 0.415906\n",
      "[1000]\ttraining's multi_logloss: 0.741558\ttraining's macroF1: 0.697399\tvalid_1's multi_logloss: 0.975712\tvalid_1's macroF1: 0.410686\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's multi_logloss: 0.858429\ttraining's macroF1: 0.640321\tvalid_1's multi_logloss: 0.98734\tvalid_1's macroF1: 0.441231\n",
      "******************** Execution ended in 00h 01m 12.32s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.904398\ttraining's macroF1: 0.620418\tvalid_1's multi_logloss: 0.940538\tvalid_1's macroF1: 0.465661\n",
      "[1000]\ttraining's multi_logloss: 0.760045\ttraining's macroF1: 0.702422\tvalid_1's multi_logloss: 0.908791\tvalid_1's macroF1: 0.473002\n",
      "[1500]\ttraining's multi_logloss: 0.666276\ttraining's macroF1: 0.741668\tvalid_1's multi_logloss: 0.890735\tvalid_1's macroF1: 0.463093\n",
      "Early stopping, best iteration is:\n",
      "[1008]\ttraining's multi_logloss: 0.758228\ttraining's macroF1: 0.702065\tvalid_1's multi_logloss: 0.908185\tvalid_1's macroF1: 0.481103\n",
      "******************** Execution ended in 00h 01m 56.45s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.885054\ttraining's macroF1: 0.630445\tvalid_1's multi_logloss: 1.04889\tvalid_1's macroF1: 0.407264\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's multi_logloss: 1.07613\ttraining's macroF1: 0.558954\tvalid_1's multi_logloss: 1.08836\tvalid_1's macroF1: 0.422184\n",
      "******************** Execution ended in 00h 00m 47.56s ********************\n",
      "######################################## 15 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.37496\ttraining's macroF1: 0.417567\tvalid_1's multi_logloss: 1.36815\tvalid_1's macroF1: 0.37249\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's multi_logloss: 1.3849\ttraining's macroF1: 0.399655\tvalid_1's multi_logloss: 1.38402\tvalid_1's macroF1: 0.401288\n",
      "******************** Execution ended in 00h 00m 30.50s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.37544\ttraining's macroF1: 0.418863\tvalid_1's multi_logloss: 1.37106\tvalid_1's macroF1: 0.375249\n",
      "[1000]\ttraining's multi_logloss: 1.36514\ttraining's macroF1: 0.425342\tvalid_1's multi_logloss: 1.35654\tvalid_1's macroF1: 0.373591\n",
      "[1500]\ttraining's multi_logloss: 1.35542\ttraining's macroF1: 0.424949\tvalid_1's multi_logloss: 1.34305\tvalid_1's macroF1: 0.381521\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's multi_logloss: 1.35631\ttraining's macroF1: 0.425201\tvalid_1's multi_logloss: 1.34429\tvalid_1's macroF1: 0.389688\n",
      "******************** Execution ended in 00h 02m 26.46s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.37382\ttraining's macroF1: 0.411264\tvalid_1's multi_logloss: 1.36931\tvalid_1's macroF1: 0.313477\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's multi_logloss: 1.38536\ttraining's macroF1: 0.40191\tvalid_1's multi_logloss: 1.38499\tvalid_1's macroF1: 0.339425\n",
      "******************** Execution ended in 00h 00m 35.93s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.37462\ttraining's macroF1: 0.426758\tvalid_1's multi_logloss: 1.37031\tvalid_1's macroF1: 0.371798\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's multi_logloss: 1.38463\ttraining's macroF1: 0.413816\tvalid_1's multi_logloss: 1.38402\tvalid_1's macroF1: 0.387975\n",
      "******************** Execution ended in 00h 00m 31.48s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.37487\ttraining's macroF1: 0.418878\tvalid_1's multi_logloss: 1.3691\tvalid_1's macroF1: 0.370912\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's multi_logloss: 1.3856\ttraining's macroF1: 0.412521\tvalid_1's multi_logloss: 1.38526\tvalid_1's macroF1: 0.392491\n",
      "******************** Execution ended in 00h 00m 31.91s ********************\n",
      "######################################## 16 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.918551\ttraining's macroF1: 0.598137\tvalid_1's multi_logloss: 1.05089\tvalid_1's macroF1: 0.392586\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's multi_logloss: 0.955338\ttraining's macroF1: 0.577132\tvalid_1's multi_logloss: 1.05838\tvalid_1's macroF1: 0.40499\n",
      "******************** Execution ended in 00h 01m 18.49s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.924051\ttraining's macroF1: 0.603044\tvalid_1's multi_logloss: 0.998525\tvalid_1's macroF1: 0.450197\n",
      "Early stopping, best iteration is:\n",
      "[496]\ttraining's multi_logloss: 0.925448\ttraining's macroF1: 0.602831\tvalid_1's multi_logloss: 0.99888\tvalid_1's macroF1: 0.453906\n",
      "******************** Execution ended in 00h 01m 31.43s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.919551\ttraining's macroF1: 0.601791\tvalid_1's multi_logloss: 1.08819\tvalid_1's macroF1: 0.382876\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's multi_logloss: 1.1138\ttraining's macroF1: 0.520841\tvalid_1's multi_logloss: 1.14185\tvalid_1's macroF1: 0.397434\n",
      "******************** Execution ended in 00h 00m 51.19s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.936037\ttraining's macroF1: 0.600651\tvalid_1's multi_logloss: 1.0358\tvalid_1's macroF1: 0.439361\n",
      "[1000]\ttraining's multi_logloss: 0.803182\ttraining's macroF1: 0.665386\tvalid_1's multi_logloss: 1.02258\tvalid_1's macroF1: 0.440919\n",
      "Early stopping, best iteration is:\n",
      "[960]\ttraining's multi_logloss: 0.811941\ttraining's macroF1: 0.662271\tvalid_1's multi_logloss: 1.02225\tvalid_1's macroF1: 0.447115\n",
      "******************** Execution ended in 00h 01m 58.57s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 0.927716\ttraining's macroF1: 0.602532\tvalid_1's multi_logloss: 1.0381\tvalid_1's macroF1: 0.416275\n",
      "[1000]\ttraining's multi_logloss: 0.794433\ttraining's macroF1: 0.665331\tvalid_1's multi_logloss: 1.02676\tvalid_1's macroF1: 0.424001\n",
      "Early stopping, best iteration is:\n",
      "[710]\ttraining's multi_logloss: 0.862563\ttraining's macroF1: 0.623763\tvalid_1's multi_logloss: 1.03197\tvalid_1's macroF1: 0.432465\n",
      "******************** Execution ended in 00h 01m 48.72s ********************\n",
      "######################################## 17 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.01486\ttraining's macroF1: 0.561339\tvalid_1's multi_logloss: 1.0112\tvalid_1's macroF1: 0.423064\n",
      "Early stopping, best iteration is:\n",
      "[307]\ttraining's multi_logloss: 1.08624\ttraining's macroF1: 0.531203\tvalid_1's multi_logloss: 1.04698\tvalid_1's macroF1: 0.432593\n",
      "******************** Execution ended in 00h 00m 50.00s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00484\ttraining's macroF1: 0.565849\tvalid_1's multi_logloss: 1.08077\tvalid_1's macroF1: 0.38782\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's multi_logloss: 1.13607\ttraining's macroF1: 0.519595\tvalid_1's multi_logloss: 1.13397\tvalid_1's macroF1: 0.40629\n",
      "******************** Execution ended in 00h 00m 44.24s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00234\ttraining's macroF1: 0.563283\tvalid_1's multi_logloss: 1.03665\tvalid_1's macroF1: 0.382802\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's multi_logloss: 1.19357\ttraining's macroF1: 0.509618\tvalid_1's multi_logloss: 1.1448\tvalid_1's macroF1: 0.402094\n",
      "******************** Execution ended in 00h 00m 41.38s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.995267\ttraining's macroF1: 0.558212\tvalid_1's multi_logloss: 1.10014\tvalid_1's macroF1: 0.390265\n",
      "[1000]\ttraining's multi_logloss: 0.888518\ttraining's macroF1: 0.618859\tvalid_1's multi_logloss: 1.08256\tvalid_1's macroF1: 0.396983\n",
      "[1500]\ttraining's multi_logloss: 0.816401\ttraining's macroF1: 0.661458\tvalid_1's multi_logloss: 1.0783\tvalid_1's macroF1: 0.397038\n",
      "Early stopping, best iteration is:\n",
      "[1039]\ttraining's multi_logloss: 0.882005\ttraining's macroF1: 0.62239\tvalid_1's multi_logloss: 1.08237\tvalid_1's macroF1: 0.403812\n",
      "******************** Execution ended in 00h 01m 46.47s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.00354\ttraining's macroF1: 0.568517\tvalid_1's multi_logloss: 1.03445\tvalid_1's macroF1: 0.410352\n",
      "Early stopping, best iteration is:\n",
      "[442]\ttraining's multi_logloss: 1.02334\ttraining's macroF1: 0.558233\tvalid_1's multi_logloss: 1.04015\tvalid_1's macroF1: 0.421464\n",
      "******************** Execution ended in 00h 01m 01.15s ********************\n",
      "######################################## 18 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09569\ttraining's macroF1: 0.499251\tvalid_1's multi_logloss: 1.07953\tvalid_1's macroF1: 0.379704\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's multi_logloss: 1.29997\ttraining's macroF1: 0.440704\tvalid_1's multi_logloss: 1.26549\tvalid_1's macroF1: 0.417514\n",
      "******************** Execution ended in 00h 00m 28.24s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09202\ttraining's macroF1: 0.501445\tvalid_1's multi_logloss: 1.03555\tvalid_1's macroF1: 0.411536\n",
      "[1000]\ttraining's multi_logloss: 1.01475\ttraining's macroF1: 0.538178\tvalid_1's multi_logloss: 1.02349\tvalid_1's macroF1: 0.400706\n",
      "Early stopping, best iteration is:\n",
      "[554]\ttraining's multi_logloss: 1.08124\ttraining's macroF1: 0.508593\tvalid_1's multi_logloss: 1.03417\tvalid_1's macroF1: 0.421566\n",
      "******************** Execution ended in 00h 00m 54.76s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09077\ttraining's macroF1: 0.494751\tvalid_1's multi_logloss: 1.10349\tvalid_1's macroF1: 0.409902\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's multi_logloss: 1.27776\ttraining's macroF1: 0.435649\tvalid_1's multi_logloss: 1.24203\tvalid_1's macroF1: 0.418176\n",
      "******************** Execution ended in 00h 00m 35.68s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08363\ttraining's macroF1: 0.506289\tvalid_1's multi_logloss: 1.10664\tvalid_1's macroF1: 0.357371\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 1.36216\ttraining's macroF1: 0.418423\tvalid_1's multi_logloss: 1.35565\tvalid_1's macroF1: 0.363516\n",
      "******************** Execution ended in 00h 00m 28.04s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08892\ttraining's macroF1: 0.492942\tvalid_1's multi_logloss: 1.08065\tvalid_1's macroF1: 0.390106\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's multi_logloss: 1.12343\ttraining's macroF1: 0.485168\tvalid_1's multi_logloss: 1.09169\tvalid_1's macroF1: 0.397953\n",
      "******************** Execution ended in 00h 00m 48.05s ********************\n",
      "######################################## 19 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.826439\ttraining's macroF1: 0.662458\tvalid_1's multi_logloss: 1.01822\tvalid_1's macroF1: 0.395141\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's multi_logloss: 1.2135\ttraining's macroF1: 0.525669\tvalid_1's multi_logloss: 1.18748\tvalid_1's macroF1: 0.42133\n",
      "******************** Execution ended in 00h 00m 47.78s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.817086\ttraining's macroF1: 0.643732\tvalid_1's multi_logloss: 1.0357\tvalid_1's macroF1: 0.397855\n",
      "[1000]\ttraining's multi_logloss: 0.667738\ttraining's macroF1: 0.729281\tvalid_1's multi_logloss: 1.02694\tvalid_1's macroF1: 0.411358\n",
      "Early stopping, best iteration is:\n",
      "[534]\ttraining's multi_logloss: 0.803068\ttraining's macroF1: 0.655008\tvalid_1's multi_logloss: 1.034\tvalid_1's macroF1: 0.420164\n",
      "******************** Execution ended in 00h 01m 27.75s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.825998\ttraining's macroF1: 0.658368\tvalid_1's multi_logloss: 1.0097\tvalid_1's macroF1: 0.413294\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's multi_logloss: 1.06823\ttraining's macroF1: 0.555598\tvalid_1's multi_logloss: 1.07941\tvalid_1's macroF1: 0.427531\n",
      "******************** Execution ended in 00h 00m 54.02s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.835316\ttraining's macroF1: 0.661427\tvalid_1's multi_logloss: 1.00511\tvalid_1's macroF1: 0.424599\n",
      "Early stopping, best iteration is:\n",
      "[233]\ttraining's multi_logloss: 0.979183\ttraining's macroF1: 0.591195\tvalid_1's multi_logloss: 1.03837\tvalid_1's macroF1: 0.429453\n",
      "******************** Execution ended in 00h 01m 05.03s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.832694\ttraining's macroF1: 0.657896\tvalid_1's multi_logloss: 1.04704\tvalid_1's macroF1: 0.433831\n",
      "[1000]\ttraining's multi_logloss: 0.677637\ttraining's macroF1: 0.734698\tvalid_1's multi_logloss: 1.02816\tvalid_1's macroF1: 0.417583\n",
      "Early stopping, best iteration is:\n",
      "[516]\ttraining's multi_logloss: 0.825759\ttraining's macroF1: 0.664054\tvalid_1's multi_logloss: 1.04593\tvalid_1's macroF1: 0.44155\n",
      "******************** Execution ended in 00h 01m 13.69s ********************\n",
      "######################################## 20 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11605\ttraining's macroF1: 0.522076\tvalid_1's multi_logloss: 1.12741\tvalid_1's macroF1: 0.377954\n",
      "Early stopping, best iteration is:\n",
      "[122]\ttraining's multi_logloss: 1.28279\ttraining's macroF1: 0.47561\tvalid_1's multi_logloss: 1.26987\tvalid_1's macroF1: 0.39294\n",
      "******************** Execution ended in 00h 00m 56.34s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.13112\ttraining's macroF1: 0.515161\tvalid_1's multi_logloss: 1.09679\tvalid_1's macroF1: 0.406703\n",
      "[1000]\ttraining's multi_logloss: 1.0268\ttraining's macroF1: 0.553321\tvalid_1's multi_logloss: 1.03939\tvalid_1's macroF1: 0.414707\n",
      "Early stopping, best iteration is:\n",
      "[904]\ttraining's multi_logloss: 1.04256\ttraining's macroF1: 0.545083\tvalid_1's multi_logloss: 1.04472\tvalid_1's macroF1: 0.417951\n",
      "******************** Execution ended in 00h 01m 54.97s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12567\ttraining's macroF1: 0.527433\tvalid_1's multi_logloss: 1.11964\tvalid_1's macroF1: 0.422463\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's multi_logloss: 1.12986\ttraining's macroF1: 0.524642\tvalid_1's multi_logloss: 1.12279\tvalid_1's macroF1: 0.429047\n",
      "******************** Execution ended in 00h 01m 26.54s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11707\ttraining's macroF1: 0.525905\tvalid_1's multi_logloss: 1.09968\tvalid_1's macroF1: 0.39666\n",
      "[1000]\ttraining's multi_logloss: 1.01115\ttraining's macroF1: 0.57122\tvalid_1's multi_logloss: 1.04173\tvalid_1's macroF1: 0.412839\n",
      "[1500]\ttraining's multi_logloss: 0.946772\ttraining's macroF1: 0.599889\tvalid_1's multi_logloss: 1.02644\tvalid_1's macroF1: 0.403552\n",
      "Early stopping, best iteration is:\n",
      "[1198]\ttraining's multi_logloss: 0.983075\ttraining's macroF1: 0.584424\tvalid_1's multi_logloss: 1.03293\tvalid_1's macroF1: 0.418636\n",
      "******************** Execution ended in 00h 02m 51.67s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12538\ttraining's macroF1: 0.523982\tvalid_1's multi_logloss: 1.12367\tvalid_1's macroF1: 0.385222\n",
      "[1000]\ttraining's multi_logloss: 1.02045\ttraining's macroF1: 0.556895\tvalid_1's multi_logloss: 1.07311\tvalid_1's macroF1: 0.388186\n",
      "Early stopping, best iteration is:\n",
      "[763]\ttraining's multi_logloss: 1.06221\ttraining's macroF1: 0.543504\tvalid_1's multi_logloss: 1.08829\tvalid_1's macroF1: 0.395825\n",
      "******************** Execution ended in 00h 02m 11.31s ********************\n",
      "######################################## 21 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.713738\ttraining's macroF1: 0.737616\tvalid_1's multi_logloss: 1.02975\tvalid_1's macroF1: 0.404859\n",
      "[1000]\ttraining's multi_logloss: 0.532966\ttraining's macroF1: 0.809743\tvalid_1's multi_logloss: 1.02261\tvalid_1's macroF1: 0.405486\n",
      "Early stopping, best iteration is:\n",
      "[671]\ttraining's multi_logloss: 0.636602\ttraining's macroF1: 0.770059\tvalid_1's multi_logloss: 1.0265\tvalid_1's macroF1: 0.421183\n",
      "******************** Execution ended in 00h 02m 22.33s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.737255\ttraining's macroF1: 0.725341\tvalid_1's multi_logloss: 0.969943\tvalid_1's macroF1: 0.418195\n",
      "[1000]\ttraining's multi_logloss: 0.554437\ttraining's macroF1: 0.797523\tvalid_1's multi_logloss: 0.95312\tvalid_1's macroF1: 0.437635\n",
      "[1500]\ttraining's multi_logloss: 0.454089\ttraining's macroF1: 0.836647\tvalid_1's multi_logloss: 0.945001\tvalid_1's macroF1: 0.421671\n",
      "Early stopping, best iteration is:\n",
      "[1101]\ttraining's multi_logloss: 0.529842\ttraining's macroF1: 0.807354\tvalid_1's multi_logloss: 0.949993\tvalid_1's macroF1: 0.447017\n",
      "******************** Execution ended in 00h 03m 11.41s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.727738\ttraining's macroF1: 0.733782\tvalid_1's multi_logloss: 0.984561\tvalid_1's macroF1: 0.436198\n",
      "[1000]\ttraining's multi_logloss: 0.545258\ttraining's macroF1: 0.805882\tvalid_1's multi_logloss: 0.964983\tvalid_1's macroF1: 0.434602\n",
      "Early stopping, best iteration is:\n",
      "[791]\ttraining's multi_logloss: 0.606198\ttraining's macroF1: 0.781809\tvalid_1's multi_logloss: 0.972995\tvalid_1's macroF1: 0.452674\n",
      "******************** Execution ended in 00h 02m 36.40s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.733114\ttraining's macroF1: 0.737938\tvalid_1's multi_logloss: 0.96138\tvalid_1's macroF1: 0.425035\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttraining's multi_logloss: 1.1908\ttraining's macroF1: 0.578255\tvalid_1's multi_logloss: 1.17409\tvalid_1's macroF1: 0.472935\n",
      "******************** Execution ended in 00h 01m 10.61s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.721026\ttraining's macroF1: 0.73605\tvalid_1's multi_logloss: 1.01575\tvalid_1's macroF1: 0.401192\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's multi_logloss: 0.944614\ttraining's macroF1: 0.656897\tvalid_1's multi_logloss: 1.05311\tvalid_1's macroF1: 0.425932\n",
      "******************** Execution ended in 00h 01m 26.99s ********************\n",
      "######################################## 22 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23012\ttraining's macroF1: 0.520012\tvalid_1's multi_logloss: 1.21286\tvalid_1's macroF1: 0.401609\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's multi_logloss: 1.37955\ttraining's macroF1: 0.469761\tvalid_1's multi_logloss: 1.37798\tvalid_1's macroF1: 0.417713\n",
      "******************** Execution ended in 00h 01m 10.70s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\ttraining's multi_logloss: 1.2332\ttraining's macroF1: 0.503329\tvalid_1's multi_logloss: 1.21021\tvalid_1's macroF1: 0.413627\n",
      "[1000]\ttraining's multi_logloss: 1.13786\ttraining's macroF1: 0.531913\tvalid_1's multi_logloss: 1.12481\tvalid_1's macroF1: 0.425565\n",
      "Early stopping, best iteration is:\n",
      "[765]\ttraining's multi_logloss: 1.17787\ttraining's macroF1: 0.518708\tvalid_1's multi_logloss: 1.1578\tvalid_1's macroF1: 0.428962\n",
      "******************** Execution ended in 00h 03m 12.15s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.22942\ttraining's macroF1: 0.52908\tvalid_1's multi_logloss: 1.22288\tvalid_1's macroF1: 0.375809\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's multi_logloss: 1.34337\ttraining's macroF1: 0.502516\tvalid_1's multi_logloss: 1.33882\tvalid_1's macroF1: 0.389267\n",
      "******************** Execution ended in 00h 01m 26.71s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.23314\ttraining's macroF1: 0.499884\tvalid_1's multi_logloss: 1.22206\tvalid_1's macroF1: 0.381084\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's multi_logloss: 1.36256\ttraining's macroF1: 0.475627\tvalid_1's multi_logloss: 1.35885\tvalid_1's macroF1: 0.39396\n",
      "******************** Execution ended in 00h 01m 23.51s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.22392\ttraining's macroF1: 0.537202\tvalid_1's multi_logloss: 1.22068\tvalid_1's macroF1: 0.338261\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's multi_logloss: 1.38449\ttraining's macroF1: 0.458089\tvalid_1's multi_logloss: 1.38413\tvalid_1's macroF1: 0.369147\n",
      "******************** Execution ended in 00h 01m 09.45s ********************\n",
      "######################################## 23 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.939977\ttraining's macroF1: 0.596421\tvalid_1's multi_logloss: 1.04119\tvalid_1's macroF1: 0.39806\n",
      "[1000]\ttraining's multi_logloss: 0.811555\ttraining's macroF1: 0.659238\tvalid_1's multi_logloss: 1.0299\tvalid_1's macroF1: 0.415351\n",
      "[1500]\ttraining's multi_logloss: 0.727339\ttraining's macroF1: 0.706651\tvalid_1's multi_logloss: 1.02646\tvalid_1's macroF1: 0.420713\n",
      "Early stopping, best iteration is:\n",
      "[1076]\ttraining's multi_logloss: 0.796985\ttraining's macroF1: 0.66614\tvalid_1's multi_logloss: 1.02896\tvalid_1's macroF1: 0.431885\n",
      "******************** Execution ended in 00h 02m 14.81s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.935457\ttraining's macroF1: 0.600373\tvalid_1's multi_logloss: 1.08107\tvalid_1's macroF1: 0.429878\n",
      "[1000]\ttraining's multi_logloss: 0.801869\ttraining's macroF1: 0.662454\tvalid_1's multi_logloss: 1.08428\tvalid_1's macroF1: 0.431291\n",
      "Early stopping, best iteration is:\n",
      "[541]\ttraining's multi_logloss: 0.920975\ttraining's macroF1: 0.610227\tvalid_1's multi_logloss: 1.08031\tvalid_1's macroF1: 0.43815\n",
      "******************** Execution ended in 00h 01m 31.33s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.934994\ttraining's macroF1: 0.59065\tvalid_1's multi_logloss: 1.04379\tvalid_1's macroF1: 0.398236\n",
      "[1000]\ttraining's multi_logloss: 0.804144\ttraining's macroF1: 0.656474\tvalid_1's multi_logloss: 1.03855\tvalid_1's macroF1: 0.402638\n",
      "[1500]\ttraining's multi_logloss: 0.718022\ttraining's macroF1: 0.70425\tvalid_1's multi_logloss: 1.03684\tvalid_1's macroF1: 0.412198\n",
      "[2000]\ttraining's multi_logloss: 0.656093\ttraining's macroF1: 0.735482\tvalid_1's multi_logloss: 1.03578\tvalid_1's macroF1: 0.403934\n",
      "Early stopping, best iteration is:\n",
      "[1524]\ttraining's multi_logloss: 0.714694\ttraining's macroF1: 0.707493\tvalid_1's multi_logloss: 1.03691\tvalid_1's macroF1: 0.41314\n",
      "******************** Execution ended in 00h 02m 47.67s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.952784\ttraining's macroF1: 0.602548\tvalid_1's multi_logloss: 0.982054\tvalid_1's macroF1: 0.455781\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's multi_logloss: 1.04813\ttraining's macroF1: 0.559132\tvalid_1's multi_logloss: 1.0254\tvalid_1's macroF1: 0.466632\n",
      "******************** Execution ended in 00h 01m 11.31s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.92687\ttraining's macroF1: 0.601254\tvalid_1's multi_logloss: 1.07512\tvalid_1's macroF1: 0.408554\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's multi_logloss: 1.0912\ttraining's macroF1: 0.535307\tvalid_1's multi_logloss: 1.12665\tvalid_1's macroF1: 0.411985\n",
      "******************** Execution ended in 00h 01m 03.05s ********************\n",
      "######################################## 24 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.688342\ttraining's macroF1: 0.738579\tvalid_1's multi_logloss: 0.959642\tvalid_1's macroF1: 0.427854\n",
      "[1000]\ttraining's multi_logloss: 0.515197\ttraining's macroF1: 0.818079\tvalid_1's multi_logloss: 0.944708\tvalid_1's macroF1: 0.438395\n",
      "[1500]\ttraining's multi_logloss: 0.427084\ttraining's macroF1: 0.843502\tvalid_1's multi_logloss: 0.942993\tvalid_1's macroF1: 0.423289\n",
      "Early stopping, best iteration is:\n",
      "[1012]\ttraining's multi_logloss: 0.512388\ttraining's macroF1: 0.820276\tvalid_1's multi_logloss: 0.944323\tvalid_1's macroF1: 0.439779\n",
      "******************** Execution ended in 00h 02m 57.75s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.687252\ttraining's macroF1: 0.739904\tvalid_1's multi_logloss: 0.996696\tvalid_1's macroF1: 0.424377\n",
      "[1000]\ttraining's multi_logloss: 0.513097\ttraining's macroF1: 0.813044\tvalid_1's multi_logloss: 0.982445\tvalid_1's macroF1: 0.413967\n",
      "Early stopping, best iteration is:\n",
      "[533]\ttraining's multi_logloss: 0.670706\ttraining's macroF1: 0.751064\tvalid_1's multi_logloss: 0.995419\tvalid_1's macroF1: 0.429177\n",
      "******************** Execution ended in 00h 03m 09.97s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.673007\ttraining's macroF1: 0.766069\tvalid_1's multi_logloss: 1.04671\tvalid_1's macroF1: 0.39205\n",
      "Early stopping, best iteration is:\n",
      "[449]\ttraining's multi_logloss: 0.701032\ttraining's macroF1: 0.75117\tvalid_1's multi_logloss: 1.04845\tvalid_1's macroF1: 0.39628\n",
      "******************** Execution ended in 00h 01m 06.44s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.687679\ttraining's macroF1: 0.735272\tvalid_1's multi_logloss: 0.991765\tvalid_1's macroF1: 0.43255\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's multi_logloss: 1.02452\ttraining's macroF1: 0.612541\tvalid_1's multi_logloss: 1.07929\tvalid_1's macroF1: 0.443053\n",
      "******************** Execution ended in 00h 01m 09.52s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.689148\ttraining's macroF1: 0.742231\tvalid_1's multi_logloss: 1.02233\tvalid_1's macroF1: 0.444152\n",
      "Early stopping, best iteration is:\n",
      "[217]\ttraining's multi_logloss: 0.899095\ttraining's macroF1: 0.661901\tvalid_1's multi_logloss: 1.05765\tvalid_1's macroF1: 0.45648\n",
      "******************** Execution ended in 00h 01m 35.04s ********************\n",
      "######################################## 25 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.31885\ttraining's macroF1: 0.46189\tvalid_1's multi_logloss: 1.30302\tvalid_1's macroF1: 0.36185\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's multi_logloss: 1.38597\ttraining's macroF1: 0.427428\tvalid_1's multi_logloss: 1.38589\tvalid_1's macroF1: 0.379528\n",
      "******************** Execution ended in 00h 00m 55.14s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.31569\ttraining's macroF1: 0.46118\tvalid_1's multi_logloss: 1.30144\tvalid_1's macroF1: 0.343696\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's multi_logloss: 1.38595\ttraining's macroF1: 0.436127\tvalid_1's multi_logloss: 1.38585\tvalid_1's macroF1: 0.358976\n",
      "******************** Execution ended in 00h 00m 50.03s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.31745\ttraining's macroF1: 0.460568\tvalid_1's multi_logloss: 1.29968\tvalid_1's macroF1: 0.405428\n",
      "Early stopping, best iteration is:\n",
      "[291]\ttraining's multi_logloss: 1.34367\ttraining's macroF1: 0.456919\tvalid_1's multi_logloss: 1.33172\tvalid_1's macroF1: 0.409836\n",
      "******************** Execution ended in 00h 01m 18.29s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.31554\ttraining's macroF1: 0.465296\tvalid_1's multi_logloss: 1.29631\tvalid_1's macroF1: 0.390629\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's multi_logloss: 1.37467\ttraining's macroF1: 0.456749\tvalid_1's multi_logloss: 1.37092\tvalid_1's macroF1: 0.401839\n",
      "******************** Execution ended in 00h 01m 01.64s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.31899\ttraining's macroF1: 0.437102\tvalid_1's multi_logloss: 1.29944\tvalid_1's macroF1: 0.382228\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's multi_logloss: 1.37897\ttraining's macroF1: 0.428379\tvalid_1's multi_logloss: 1.37649\tvalid_1's macroF1: 0.384585\n",
      "******************** Execution ended in 00h 01m 11.33s ********************\n",
      "######################################## 26 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17696\ttraining's macroF1: 0.548018\tvalid_1's multi_logloss: 1.1747\tvalid_1's macroF1: 0.408201\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's multi_logloss: 1.36942\ttraining's macroF1: 0.503065\tvalid_1's multi_logloss: 1.36584\tvalid_1's macroF1: 0.417129\n",
      "******************** Execution ended in 00h 00m 53.15s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17567\ttraining's macroF1: 0.528182\tvalid_1's multi_logloss: 1.17732\tvalid_1's macroF1: 0.401766\n",
      "[1000]\ttraining's multi_logloss: 1.06627\ttraining's macroF1: 0.559984\tvalid_1's multi_logloss: 1.10973\tvalid_1's macroF1: 0.406289\n",
      "Early stopping, best iteration is:\n",
      "[925]\ttraining's multi_logloss: 1.07949\ttraining's macroF1: 0.55587\tvalid_1's multi_logloss: 1.11526\tvalid_1's macroF1: 0.408363\n",
      "******************** Execution ended in 00h 02m 13.06s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17916\ttraining's macroF1: 0.526494\tvalid_1's multi_logloss: 1.16251\tvalid_1's macroF1: 0.39059\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's multi_logloss: 1.37795\ttraining's macroF1: 0.477499\tvalid_1's multi_logloss: 1.37535\tvalid_1's macroF1: 0.416347\n",
      "******************** Execution ended in 00h 00m 49.04s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.17875\ttraining's macroF1: 0.523915\tvalid_1's multi_logloss: 1.15453\tvalid_1's macroF1: 0.39392\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's multi_logloss: 1.37319\ttraining's macroF1: 0.474235\tvalid_1's multi_logloss: 1.3688\tvalid_1's macroF1: 0.407881\n",
      "******************** Execution ended in 00h 00m 48.95s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18615\ttraining's macroF1: 0.52042\tvalid_1's multi_logloss: 1.14071\tvalid_1's macroF1: 0.417713\n",
      "[1000]\ttraining's multi_logloss: 1.08136\ttraining's macroF1: 0.550366\tvalid_1's multi_logloss: 1.04414\tvalid_1's macroF1: 0.437655\n",
      "Early stopping, best iteration is:\n",
      "[922]\ttraining's multi_logloss: 1.09436\ttraining's macroF1: 0.545142\tvalid_1's multi_logloss: 1.05385\tvalid_1's macroF1: 0.441469\n",
      "******************** Execution ended in 00h 02m 17.00s ********************\n",
      "######################################## 27 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08434\ttraining's macroF1: 0.518715\tvalid_1's multi_logloss: 1.06896\tvalid_1's macroF1: 0.418104\n",
      "[1000]\ttraining's multi_logloss: 0.979118\ttraining's macroF1: 0.559381\tvalid_1's multi_logloss: 1.02197\tvalid_1's macroF1: 0.429962\n",
      "Early stopping, best iteration is:\n",
      "[882]\ttraining's multi_logloss: 0.998709\ttraining's macroF1: 0.549866\tvalid_1's multi_logloss: 1.02822\tvalid_1's macroF1: 0.434177\n",
      "******************** Execution ended in 00h 01m 50.49s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08303\ttraining's macroF1: 0.544856\tvalid_1's multi_logloss: 1.09733\tvalid_1's macroF1: 0.428908\n",
      "[1000]\ttraining's multi_logloss: 0.975924\ttraining's macroF1: 0.575394\tvalid_1's multi_logloss: 1.06254\tvalid_1's macroF1: 0.426467\n",
      "[1500]\ttraining's multi_logloss: 0.909394\ttraining's macroF1: 0.61139\tvalid_1's multi_logloss: 1.05646\tvalid_1's macroF1: 0.415632\n",
      "Early stopping, best iteration is:\n",
      "[1071]\ttraining's multi_logloss: 0.96507\ttraining's macroF1: 0.580613\tvalid_1's multi_logloss: 1.05999\tvalid_1's macroF1: 0.433408\n",
      "******************** Execution ended in 00h 02m 01.58s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07674\ttraining's macroF1: 0.537258\tvalid_1's multi_logloss: 1.10438\tvalid_1's macroF1: 0.364268\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's multi_logloss: 1.16312\ttraining's macroF1: 0.51597\tvalid_1's multi_logloss: 1.15804\tvalid_1's macroF1: 0.372176\n",
      "******************** Execution ended in 00h 01m 02.64s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0754\ttraining's macroF1: 0.540094\tvalid_1's multi_logloss: 1.09988\tvalid_1's macroF1: 0.35717\n",
      "Early stopping, best iteration is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12]\ttraining's multi_logloss: 1.37007\ttraining's macroF1: 0.450719\tvalid_1's multi_logloss: 1.36639\tvalid_1's macroF1: 0.377985\n",
      "******************** Execution ended in 00h 00m 43.07s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08546\ttraining's macroF1: 0.525269\tvalid_1's multi_logloss: 1.08111\tvalid_1's macroF1: 0.411698\n",
      "[1000]\ttraining's multi_logloss: 0.980821\ttraining's macroF1: 0.566516\tvalid_1's multi_logloss: 1.044\tvalid_1's macroF1: 0.424715\n",
      "[1500]\ttraining's multi_logloss: 0.914002\ttraining's macroF1: 0.601389\tvalid_1's multi_logloss: 1.03611\tvalid_1's macroF1: 0.410487\n",
      "Early stopping, best iteration is:\n",
      "[1048]\ttraining's multi_logloss: 0.973402\ttraining's macroF1: 0.571129\tvalid_1's multi_logloss: 1.04278\tvalid_1's macroF1: 0.425469\n",
      "******************** Execution ended in 00h 01m 59.83s ********************\n",
      "######################################## 28 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12557\ttraining's macroF1: 0.521951\tvalid_1's multi_logloss: 1.11065\tvalid_1's macroF1: 0.405934\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttraining's multi_logloss: 1.15546\ttraining's macroF1: 0.513864\tvalid_1's multi_logloss: 1.13298\tvalid_1's macroF1: 0.413609\n",
      "******************** Execution ended in 00h 01m 04.50s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12514\ttraining's macroF1: 0.510704\tvalid_1's multi_logloss: 1.08834\tvalid_1's macroF1: 0.416351\n",
      "[1000]\ttraining's multi_logloss: 1.02975\ttraining's macroF1: 0.551115\tvalid_1's multi_logloss: 1.04239\tvalid_1's macroF1: 0.42359\n",
      "[1500]\ttraining's multi_logloss: 0.972315\ttraining's macroF1: 0.568143\tvalid_1's multi_logloss: 1.02919\tvalid_1's macroF1: 0.426329\n",
      "Early stopping, best iteration is:\n",
      "[1188]\ttraining's multi_logloss: 1.00581\ttraining's macroF1: 0.557142\tvalid_1's multi_logloss: 1.03492\tvalid_1's macroF1: 0.438867\n",
      "******************** Execution ended in 00h 02m 05.17s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11863\ttraining's macroF1: 0.531104\tvalid_1's multi_logloss: 1.08251\tvalid_1's macroF1: 0.383531\n",
      "Early stopping, best iteration is:\n",
      "[164]\ttraining's multi_logloss: 1.25495\ttraining's macroF1: 0.493086\tvalid_1's multi_logloss: 1.21279\tvalid_1's macroF1: 0.409939\n",
      "******************** Execution ended in 00h 00m 51.06s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12626\ttraining's macroF1: 0.496845\tvalid_1's multi_logloss: 1.08223\tvalid_1's macroF1: 0.409501\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's multi_logloss: 1.24062\ttraining's macroF1: 0.475911\tvalid_1's multi_logloss: 1.19757\tvalid_1's macroF1: 0.429328\n",
      "******************** Execution ended in 00h 00m 53.86s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.12841\ttraining's macroF1: 0.513935\tvalid_1's multi_logloss: 1.12842\tvalid_1's macroF1: 0.347845\n",
      "[1000]\ttraining's multi_logloss: 1.03472\ttraining's macroF1: 0.546084\tvalid_1's multi_logloss: 1.09175\tvalid_1's macroF1: 0.39399\n",
      "[1500]\ttraining's multi_logloss: 0.978425\ttraining's macroF1: 0.569934\tvalid_1's multi_logloss: 1.08391\tvalid_1's macroF1: 0.398703\n",
      "[2000]\ttraining's multi_logloss: 0.935205\ttraining's macroF1: 0.596955\tvalid_1's multi_logloss: 1.0779\tvalid_1's macroF1: 0.402995\n",
      "[2500]\ttraining's multi_logloss: 0.898748\ttraining's macroF1: 0.613912\tvalid_1's multi_logloss: 1.07636\tvalid_1's macroF1: 0.409126\n",
      "Early stopping, best iteration is:\n",
      "[2152]\ttraining's multi_logloss: 0.923447\ttraining's macroF1: 0.60164\tvalid_1's multi_logloss: 1.07803\tvalid_1's macroF1: 0.41581\n",
      "******************** Execution ended in 00h 03m 20.67s ********************\n",
      "######################################## 29 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.719589\ttraining's macroF1: 0.750755\tvalid_1's multi_logloss: 0.97977\tvalid_1's macroF1: 0.398341\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's multi_logloss: 1.36311\ttraining's macroF1: 0.508131\tvalid_1's multi_logloss: 1.36042\tvalid_1's macroF1: 0.418487\n",
      "******************** Execution ended in 00h 01m 08.28s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.711864\ttraining's macroF1: 0.754671\tvalid_1's multi_logloss: 1.01012\tvalid_1's macroF1: 0.413973\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's multi_logloss: 1.19349\ttraining's macroF1: 0.594277\tvalid_1's multi_logloss: 1.21395\tvalid_1's macroF1: 0.423895\n",
      "******************** Execution ended in 00h 01m 13.50s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.710701\ttraining's macroF1: 0.755547\tvalid_1's multi_logloss: 1.05021\tvalid_1's macroF1: 0.362362\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's multi_logloss: 1.24132\ttraining's macroF1: 0.603405\tvalid_1's multi_logloss: 1.26703\tvalid_1's macroF1: 0.373372\n",
      "******************** Execution ended in 00h 01m 16.83s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.715186\ttraining's macroF1: 0.746288\tvalid_1's multi_logloss: 0.974569\tvalid_1's macroF1: 0.40967\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 1.33696\ttraining's macroF1: 0.550427\tvalid_1's multi_logloss: 1.33134\tvalid_1's macroF1: 0.434943\n",
      "******************** Execution ended in 00h 01m 07.72s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.715362\ttraining's macroF1: 0.746062\tvalid_1's multi_logloss: 1.00103\tvalid_1's macroF1: 0.409664\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's multi_logloss: 1.33786\ttraining's macroF1: 0.549388\tvalid_1's multi_logloss: 1.33625\tvalid_1's macroF1: 0.429657\n",
      "******************** Execution ended in 00h 01m 12.14s ********************\n",
      "######################################## 30 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11662\ttraining's macroF1: 0.525632\tvalid_1's multi_logloss: 1.07465\tvalid_1's macroF1: 0.441222\n",
      "[1000]\ttraining's multi_logloss: 1.01707\ttraining's macroF1: 0.56435\tvalid_1's multi_logloss: 1.02787\tvalid_1's macroF1: 0.434452\n",
      "Early stopping, best iteration is:\n",
      "[813]\ttraining's multi_logloss: 1.04729\ttraining's macroF1: 0.55179\tvalid_1's multi_logloss: 1.03764\tvalid_1's macroF1: 0.450025\n",
      "******************** Execution ended in 00h 01m 57.07s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11454\ttraining's macroF1: 0.517505\tvalid_1's multi_logloss: 1.10015\tvalid_1's macroF1: 0.408785\n",
      "[1000]\ttraining's multi_logloss: 1.01972\ttraining's macroF1: 0.556851\tvalid_1's multi_logloss: 1.05506\tvalid_1's macroF1: 0.435002\n",
      "[1500]\ttraining's multi_logloss: 0.96076\ttraining's macroF1: 0.573575\tvalid_1's multi_logloss: 1.0437\tvalid_1's macroF1: 0.441693\n",
      "Early stopping, best iteration is:\n",
      "[1452]\ttraining's multi_logloss: 0.965625\ttraining's macroF1: 0.575497\tvalid_1's multi_logloss: 1.04432\tvalid_1's macroF1: 0.4448\n",
      "******************** Execution ended in 00h 02m 49.26s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.10483\ttraining's macroF1: 0.521866\tvalid_1's multi_logloss: 1.12492\tvalid_1's macroF1: 0.390451\n",
      "[1000]\ttraining's multi_logloss: 1.00907\ttraining's macroF1: 0.55049\tvalid_1's multi_logloss: 1.08368\tvalid_1's macroF1: 0.394987\n",
      "Early stopping, best iteration is:\n",
      "[686]\ttraining's multi_logloss: 1.06124\ttraining's macroF1: 0.534539\tvalid_1's multi_logloss: 1.10236\tvalid_1's macroF1: 0.402004\n",
      "******************** Execution ended in 00h 01m 57.47s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.11021\ttraining's macroF1: 0.518434\tvalid_1's multi_logloss: 1.09809\tvalid_1's macroF1: 0.380447\n",
      "[1000]\ttraining's multi_logloss: 1.01209\ttraining's macroF1: 0.551544\tvalid_1's multi_logloss: 1.05822\tvalid_1's macroF1: 0.372464\n",
      "Early stopping, best iteration is:\n",
      "[597]\ttraining's multi_logloss: 1.08543\ttraining's macroF1: 0.522497\tvalid_1's multi_logloss: 1.08343\tvalid_1's macroF1: 0.393024\n",
      "******************** Execution ended in 00h 02m 06.41s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.0989\ttraining's macroF1: 0.528766\tvalid_1's multi_logloss: 1.09555\tvalid_1's macroF1: 0.409107\n",
      "[1000]\ttraining's multi_logloss: 0.999217\ttraining's macroF1: 0.557571\tvalid_1's multi_logloss: 1.0527\tvalid_1's macroF1: 0.403524\n",
      "Early stopping, best iteration is:\n",
      "[871]\ttraining's multi_logloss: 1.0191\ttraining's macroF1: 0.554131\tvalid_1's multi_logloss: 1.05817\tvalid_1's macroF1: 0.413263\n",
      "******************** Execution ended in 00h 01m 56.23s ********************\n",
      "######################################## 31 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18256\ttraining's macroF1: 0.581548\tvalid_1's multi_logloss: 1.18877\tvalid_1's macroF1: 0.397917\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's multi_logloss: 1.29221\ttraining's macroF1: 0.556562\tvalid_1's multi_logloss: 1.2885\tvalid_1's macroF1: 0.410963\n",
      "******************** Execution ended in 00h 01m 09.25s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18513\ttraining's macroF1: 0.574894\tvalid_1's multi_logloss: 1.16794\tvalid_1's macroF1: 0.399255\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's multi_logloss: 1.37962\ttraining's macroF1: 0.51153\tvalid_1's multi_logloss: 1.37805\tvalid_1's macroF1: 0.422815\n",
      "******************** Execution ended in 00h 00m 47.78s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18334\ttraining's macroF1: 0.579578\tvalid_1's multi_logloss: 1.17775\tvalid_1's macroF1: 0.389024\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's multi_logloss: 1.38116\ttraining's macroF1: 0.512596\tvalid_1's multi_logloss: 1.37998\tvalid_1's macroF1: 0.432702\n",
      "******************** Execution ended in 00h 00m 47.89s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18954\ttraining's macroF1: 0.57831\tvalid_1's multi_logloss: 1.17758\tvalid_1's macroF1: 0.425661\n",
      "[1000]\ttraining's multi_logloss: 1.07122\ttraining's macroF1: 0.60448\tvalid_1's multi_logloss: 1.08246\tvalid_1's macroF1: 0.433444\n",
      "[1500]\ttraining's multi_logloss: 0.988095\ttraining's macroF1: 0.62996\tvalid_1's multi_logloss: 1.03258\tvalid_1's macroF1: 0.448637\n",
      "[2000]\ttraining's multi_logloss: 0.924214\ttraining's macroF1: 0.654796\tvalid_1's multi_logloss: 1.0059\tvalid_1's macroF1: 0.452362\n",
      "Early stopping, best iteration is:\n",
      "[1879]\ttraining's multi_logloss: 0.938404\ttraining's macroF1: 0.645981\tvalid_1's multi_logloss: 1.01138\tvalid_1's macroF1: 0.453925\n",
      "******************** Execution ended in 00h 04m 38.37s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.18427\ttraining's macroF1: 0.589365\tvalid_1's multi_logloss: 1.18646\tvalid_1's macroF1: 0.412608\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's multi_logloss: 1.2714\ttraining's macroF1: 0.566468\tvalid_1's multi_logloss: 1.26651\tvalid_1's macroF1: 0.419268\n",
      "******************** Execution ended in 00h 01m 23.08s ********************\n",
      "######################################## 32 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.08091\ttraining's macroF1: 0.529718\tvalid_1's multi_logloss: 1.09659\tvalid_1's macroF1: 0.404214\n",
      "[1000]\ttraining's multi_logloss: 0.97915\ttraining's macroF1: 0.580411\tvalid_1's multi_logloss: 1.07145\tvalid_1's macroF1: 0.400733\n",
      "Early stopping, best iteration is:\n",
      "[667]\ttraining's multi_logloss: 1.03946\ttraining's macroF1: 0.548391\tvalid_1's multi_logloss: 1.08186\tvalid_1's macroF1: 0.412184\n",
      "******************** Execution ended in 00h 01m 49.41s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07015\ttraining's macroF1: 0.534435\tvalid_1's multi_logloss: 1.07938\tvalid_1's macroF1: 0.387561\n",
      "[1000]\ttraining's multi_logloss: 0.971841\ttraining's macroF1: 0.574201\tvalid_1's multi_logloss: 1.0515\tvalid_1's macroF1: 0.404259\n",
      "Early stopping, best iteration is:\n",
      "[836]\ttraining's multi_logloss: 0.9978\ttraining's macroF1: 0.564369\tvalid_1's multi_logloss: 1.05526\tvalid_1's macroF1: 0.409947\n",
      "******************** Execution ended in 00h 02m 11.74s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07474\ttraining's macroF1: 0.534104\tvalid_1's multi_logloss: 1.05429\tvalid_1's macroF1: 0.426063\n",
      "[1000]\ttraining's multi_logloss: 0.978477\ttraining's macroF1: 0.572001\tvalid_1's multi_logloss: 1.0218\tvalid_1's macroF1: 0.40037\n",
      "Early stopping, best iteration is:\n",
      "[566]\ttraining's multi_logloss: 1.0573\ttraining's macroF1: 0.533867\tvalid_1's multi_logloss: 1.04551\tvalid_1's macroF1: 0.430557\n",
      "******************** Execution ended in 00h 01m 36.06s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07881\ttraining's macroF1: 0.531746\tvalid_1's multi_logloss: 1.07162\tvalid_1's macroF1: 0.382208\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's multi_logloss: 1.22789\ttraining's macroF1: 0.472006\tvalid_1's multi_logloss: 1.19309\tvalid_1's macroF1: 0.404364\n",
      "******************** Execution ended in 00h 01m 03.58s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.07428\ttraining's macroF1: 0.525323\tvalid_1's multi_logloss: 1.11557\tvalid_1's macroF1: 0.387189\n",
      "Early stopping, best iteration is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\ttraining's multi_logloss: 1.37852\ttraining's macroF1: 0.434584\tvalid_1's multi_logloss: 1.37656\tvalid_1's macroF1: 0.401444\n",
      "******************** Execution ended in 00h 00m 49.45s ********************\n",
      "######################################## 33 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1064\ttraining's macroF1: 0.488266\tvalid_1's multi_logloss: 1.07325\tvalid_1's macroF1: 0.394684\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's multi_logloss: 1.2127\ttraining's macroF1: 0.450598\tvalid_1's multi_logloss: 1.15268\tvalid_1's macroF1: 0.407758\n",
      "******************** Execution ended in 00h 00m 44.34s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1077\ttraining's macroF1: 0.485963\tvalid_1's multi_logloss: 1.08194\tvalid_1's macroF1: 0.420535\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's multi_logloss: 1.13698\ttraining's macroF1: 0.47932\tvalid_1's multi_logloss: 1.09383\tvalid_1's macroF1: 0.427103\n",
      "******************** Execution ended in 00h 00m 55.39s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.1044\ttraining's macroF1: 0.495024\tvalid_1's multi_logloss: 1.05884\tvalid_1's macroF1: 0.403943\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's multi_logloss: 1.21489\ttraining's macroF1: 0.466274\tvalid_1's multi_logloss: 1.14585\tvalid_1's macroF1: 0.431841\n",
      "******************** Execution ended in 00h 00m 42.31s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09677\ttraining's macroF1: 0.500122\tvalid_1's multi_logloss: 1.11492\tvalid_1's macroF1: 0.378406\n",
      "[1000]\ttraining's multi_logloss: 1.03164\ttraining's macroF1: 0.529419\tvalid_1's multi_logloss: 1.10653\tvalid_1's macroF1: 0.380256\n",
      "[1500]\ttraining's multi_logloss: 0.989453\ttraining's macroF1: 0.551891\tvalid_1's multi_logloss: 1.10763\tvalid_1's macroF1: 0.391433\n",
      "Early stopping, best iteration is:\n",
      "[1207]\ttraining's multi_logloss: 1.0127\ttraining's macroF1: 0.539908\tvalid_1's multi_logloss: 1.10609\tvalid_1's macroF1: 0.390448\n",
      "******************** Execution ended in 00h 01m 42.94s ********************\n",
      "============================== 5 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 1.09492\ttraining's macroF1: 0.488593\tvalid_1's multi_logloss: 1.085\tvalid_1's macroF1: 0.376514\n",
      "[1000]\ttraining's multi_logloss: 1.02761\ttraining's macroF1: 0.526798\tvalid_1's multi_logloss: 1.07311\tvalid_1's macroF1: 0.392711\n",
      "[1500]\ttraining's multi_logloss: 0.984064\ttraining's macroF1: 0.545665\tvalid_1's multi_logloss: 1.07064\tvalid_1's macroF1: 0.400637\n",
      "Early stopping, best iteration is:\n",
      "[1252]\ttraining's multi_logloss: 1.00389\ttraining's macroF1: 0.53987\tvalid_1's multi_logloss: 1.07041\tvalid_1's macroF1: 0.40614\n",
      "******************** Execution ended in 00h 01m 47.17s ********************\n",
      "######################################## 34 of 50 iterations ########################################\n",
      "============================== 1 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.828022\ttraining's macroF1: 0.660976\tvalid_1's multi_logloss: 0.998009\tvalid_1's macroF1: 0.43587\n",
      "[1000]\ttraining's multi_logloss: 0.674939\ttraining's macroF1: 0.738158\tvalid_1's multi_logloss: 0.98881\tvalid_1's macroF1: 0.444356\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's multi_logloss: 0.777478\ttraining's macroF1: 0.686118\tvalid_1's multi_logloss: 0.992805\tvalid_1's macroF1: 0.449331\n",
      "******************** Execution ended in 00h 02m 20.48s ********************\n",
      "============================== 2 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.823845\ttraining's macroF1: 0.65004\tvalid_1's multi_logloss: 1.03061\tvalid_1's macroF1: 0.395931\n",
      "Early stopping, best iteration is:\n",
      "[321]\ttraining's multi_logloss: 0.910956\ttraining's macroF1: 0.606442\tvalid_1's multi_logloss: 1.03726\tvalid_1's macroF1: 0.413536\n",
      "******************** Execution ended in 00h 01m 45.18s ********************\n",
      "============================== 3 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n",
      "[500]\ttraining's multi_logloss: 0.810223\ttraining's macroF1: 0.669946\tvalid_1's multi_logloss: 1.1121\tvalid_1's macroF1: 0.396743\n",
      "Early stopping, best iteration is:\n",
      "[484]\ttraining's multi_logloss: 0.817084\ttraining's macroF1: 0.665454\tvalid_1's multi_logloss: 1.11163\tvalid_1's macroF1: 0.397514\n",
      "******************** Execution ended in 00h 02m 06.64s ********************\n",
      "============================== 4 of 5 folds ==============================\n",
      "Training until validation scores don't improve for 500 rounds\n"
     ]
    }
   ],
   "source": [
    "total_shap_df  = pd.DataFrame()\n",
    "NUM_ITERATIONS = 50\n",
    "for SEED in range(NUM_ITERATIONS):\n",
    "    print('#'*40, '{} of {} iterations'.format(SEED+1, NUM_ITERATIONS), '#' * 40)\n",
    "    params = {'max_depth': np.random.choice([5, 6, 7, 8, 10, 12, -1]),\n",
    "             'learning_rate': np.random.rand() * 0.02,\n",
    "              'colsample_bytree': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'subsample': np.random.rand() * (1 - 0.5) + 0.5,\n",
    "              'min_split_gain': np.random.rand() * 0.2,\n",
    "              'num_leaves': np.random.choice([32, 48, 64]),\n",
    "              'reg_alpha': np.random.rand() * 2,\n",
    "              'reg_lambda': np.random.rand() *2,\n",
    "              'bagging_freq': np.random.randint(4) +1,\n",
    "              'min_child_weight': np.random.randint(100) + 20\n",
    "             }\n",
    "    temp_shap_df = extract_good_features_using_shap_LGB(params, SEED)\n",
    "    total_shap_df = pd.concat([total_shap_df, temp_shap_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_sorted_df = total_shap_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "feat_imp_sorted_df = total_shap_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "features_top_shap = shap_sorted_df['feature'][:500]\n",
    "features_top_feat_imp = feat_imp_sorted_df['feature'][:500]\n",
    "top_features = pd.Series(features_top_shap.tolist() + features_top_feat_imp.tolist())\n",
    "top_features = top_features.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train[top_features].copy()\n",
    "new_test = test[top_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('new_train shape:', new_train.shape, 'new_test shape:', new_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorical_feats = [col for col in top_features if col in categorical_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LGB_OOF(params, categorical_feats, N_FOLDs, SEED=1989):\n",
    "    clf = lgb.LGBMClassifier(objective='multiclass',\n",
    "                             random_state=1989,\n",
    "                             max_depth=params['max_depth'], \n",
    "                             learning_rate=params['learning_rate'],  \n",
    "                             silent=True, \n",
    "                             metric='multi_logloss',\n",
    "                             n_jobs=-1, n_estimators=10000, \n",
    "                             class_weight='balanced',\n",
    "                             colsample_bytree = params['colsample_bytree'], \n",
    "                             min_split_gain= params['min_split_gain'], \n",
    "                             bagging_freq = params['bagging_freq'],\n",
    "                             min_child_weight=params['min_child_weight'],\n",
    "                             num_leaves = params['num_leaves'], \n",
    "                             subsample = params['subsample'],\n",
    "                             reg_alpha= params['reg_alpha'],\n",
    "                             reg_lambda= params['reg_lambda'],\n",
    "                             num_class=len(np.unique(y)),\n",
    "                             bagging_seed=SEED,\n",
    "                             seed=SEED,\n",
    "                            )\n",
    "\n",
    "    kfold = 10\n",
    "    kf = StratifiedKFold(n_splits=kfold, shuffle=True)\n",
    "    feat_importance_df  = pd.DataFrame()\n",
    "    predicts_result = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(new_train, y)):\n",
    "        print('='*30, '{} of {} folds'.format(i+1, kfold), '='*30)\n",
    "        start = time.time()\n",
    "        X_train, X_val = new_train.iloc[train_index], new_train.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "        clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric=evaluate_macroF1_lgb,categorical_feature=new_categorical_feats,\n",
    "                early_stopping_rounds=500, verbose=500)\n",
    "        shap_values = shap.TreeExplainer(clf.booster_).shap_values(X_train)\n",
    "        fold_importance_df  = pd.DataFrame()\n",
    "        fold_importance_df['feature'] = X_train.columns\n",
    "        fold_importance_df['shap_values'] = abs(np.array(shap_values)[:, :].mean(1).mean(0))\n",
    "        fold_importance_df['feat_imp'] = clf.feature_importances_\n",
    "        feat_importance_df = pd.concat([feat_importance_df, fold_importance_df])\n",
    "        predicts_result.append(clf.predict(new_test))\n",
    "        print_execution_time(start)\n",
    "    return predicts_result, feat_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': 6,\n",
    "         'learning_rate': 0.002,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'subsample': 0.8,\n",
    "          'min_split_gain': 0.02,\n",
    "          'num_leaves': 48,\n",
    "          'reg_alpha': 0.04,\n",
    "          'reg_lambda': 0.073,\n",
    "          'bagging_freq': 2,\n",
    "          'min_child_weight': 40\n",
    "         }\n",
    "\n",
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(params, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "feat_importance_df_shap = feat_importance_df.groupby('feature').mean().sort_values('shap_values', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df_shap.shap_values[:num_features], y=feat_importance_df_shap.feature[:num_features], ax=ax[0])\n",
    "ax[0].set_title('Feature importance based on shap values')\n",
    "\n",
    "feat_importance_df = feat_importance_df.groupby('feature').mean().sort_values('feat_imp', ascending=False).reset_index()\n",
    "\n",
    "num_features = 50\n",
    "sns.barplot(x=feat_importance_df.shap_values[:num_features], y=feat_importance_df.feature[:num_features], ax=ax[1])\n",
    "ax[1].set_title('Feaure importance based on feature importance from lgbm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "submission.to_csv('submission_with_new_feature_set.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized serach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_param = None\n",
    "lowest_cv = 1000\n",
    "total_iteration = 100\n",
    "for i in range(total_iteration):\n",
    "    print('-'*20, 'For {} of {} iterations'.format(i+1, total_iteration), '-'*20)\n",
    "    learning_rate = np.random.rand() * 0.02\n",
    "    n_folds = 3\n",
    "\n",
    "    num_class = len(np.unique(y))\n",
    "\n",
    "    params = {}\n",
    "    params['application'] = 'multiclass'\n",
    "    params['metric'] = 'multi_logloss'\n",
    "    params['num_class'] = num_class\n",
    "    params['class_weight'] = 'balanced'\n",
    "    params['num_leaves'] = np.random.randint(24, 48)\n",
    "    params['max_depth'] = np.random.randint(5, 8)\n",
    "    params['min_child_weight'] = np.random.randint(5, 50)\n",
    "    params['min_split_gain'] = np.random.rand() * 0.09\n",
    "    params['colsample_bytree'] = np.random.rand() * (0.9 - 0.1) + 0.1\n",
    "    params['subsample'] = np.random.rand() * (1 - 0.8) + 0.8\n",
    "    params['bagging_freq'] = np.random.randint(1, 5)\n",
    "    params['bagging_seed'] = np.random.randint(1, 5)\n",
    "    params['reg_alpha'] = np.random.rand() * 2\n",
    "    params['reg_lambda'] = np.random.rand() * 2\n",
    "    params['learning_rate'] = np.random.rand() * 0.02\n",
    "    params['seed']  =1989\n",
    "\n",
    "    d_train = lgb.Dataset(data=new_train, label=y.values-1, categorical_feature=new_categorical_feats, free_raw_data=False)\n",
    "    cv_results = lgb.cv(params=params, train_set=d_train, num_boost_round=10000, categorical_feature=new_categorical_feats,\n",
    "                        nfold=n_folds, stratified=True, shuffle=True, early_stopping_rounds=1, verbose_eval=1000)\n",
    "\n",
    "    min_cv_results = min(cv_results['multi_logloss-mean'])\n",
    "\n",
    "    if min_cv_results < lowest_cv:\n",
    "        lowest_cv = min_cv_results\n",
    "        optimized_param = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_Folds = 20\n",
    "SEED = 1989\n",
    "predicts_result, feat_importance_df = LGB_OOF(optimized_param, new_categorical_feats, N_Folds, SEED=1989)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission['Target'] = np.array(predicts_result).mean(axis=0).round().astype(int)\n",
    "# submission.to_csv('submission_shap_randomized_search.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
