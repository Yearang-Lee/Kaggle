{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고커널 : https://www.kaggle.com/submarineering/submarineering-even-better-public-score-until-now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path = \"../input/statoil-iceberg-submissions\"\n",
    "all_files = os.listdir(sub_path)\n",
    "all_files = all_files[1:3]\n",
    "all_files.append('submission38.csv')\n",
    "all_files.append('submission43.csv')\n",
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and concatenate submissions\n",
    "out1 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_200_ens_densenet.csv\", index_col=0)\n",
    "out2 = pd.read_csv(\"../input/statoil-iceberg-submissions/sub_TF_keras.csv\", index_col=0)\n",
    "out3 = pd.read_csv(\"../input/submission38-lb01448/submission38.csv\", index_col=0)\n",
    "out4 = pd.read_csv(\"../input/submission38-lb01448/submission43.csv\", index_col=0)\n",
    "concat_sub = pd.concat([out1, out2, out3, out4], axis=1)\n",
    "cols = list(map(lambda x: \"is_iceberg_\" + str(x), range(len(concat_sub.columns))))\n",
    "concat_sub.columns = cols\n",
    "concat_sub.reset_index(inplace=True)\n",
    "concat_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation\n",
    "concat_sub.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data fields ready for stacking\n",
    "concat_sub['is_iceberg_max'] = concat_sub.iloc[:, 1:6].max(axis=1)\n",
    "concat_sub['is_iceberg_min'] = concat_sub.iloc[:, 1:6].min(axis=1)\n",
    "concat_sub['is_iceberg_mean'] = concat_sub.iloc[:, 1:6].mean(axis=1)\n",
    "concat_sub['is_iceberg_median'] = concat_sub.iloc[:, 1:6].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up cutoff threshold for lower and upper bounds, easy to twist \n",
    "cutoff_lo = 0.8\n",
    "cutoff_hi = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_sub['is_iceberg'] = concat_sub['is_iceberg_mean']\n",
    "#concat_sub[['id', 'is_iceberg']].to_csv('stack_mean.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_sub['is_iceberg'] = concat_sub['is_iceberg_median']\n",
    "#concat_sub[['id', 'is_iceberg']].to_csv('stack_median.csv', index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PushOut + Median Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), 1, \n",
    "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "#                                             0, concat_sub['is_iceberg_median']))\n",
    "#concat_sub[['id', 'is_iceberg']].to_csv('stack_pushout_median.csv', \n",
    "#                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax + Mean Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "#                                    concat_sub['is_iceberg_max'], \n",
    "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "#                                             concat_sub['is_iceberg_min'], \n",
    "#                                             concat_sub['is_iceberg_mean']))\n",
    "#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_mean.csv', \n",
    "#                                        index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax + Median Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:6] > cutoff_lo, axis=1), \n",
    "#                                    concat_sub['is_iceberg_max'], \n",
    "#                                    np.where(np.all(concat_sub.iloc[:,1:6] < cutoff_hi, axis=1),\n",
    "#                                             concat_sub['is_iceberg_min'], \n",
    "#                                             concat_sub['is_iceberg_median']))\n",
    "#concat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\n",
    "#concat_sub[['id', 'is_iceberg']].to_csv('stack_minmax_median.csv', \n",
    "#                                       index=False, float_format='%.6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MinMax + BestBase Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model with best base performance\n",
    "sub_base = pd.read_csv('../input/submission38-lb01448/submission43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_sub['is_iceberg_base'] = sub_base['is_iceberg']\n",
    "concat_sub['is_iceberg'] = np.where(np.all(concat_sub.iloc[:,1:4] > cutoff_lo, axis=1), \n",
    "                                    concat_sub['is_iceberg_max'], \n",
    "                                    np.where(np.all(concat_sub.iloc[:,1:4] < cutoff_hi, axis=1),\n",
    "                                             concat_sub['is_iceberg_min'], \n",
    "                                             concat_sub['is_iceberg_base']))\n",
    "concat_sub['is_iceberg'] = np.clip(concat_sub['is_iceberg'].values, 0.001, 0.999)\n",
    "concat_sub[['id', 'is_iceberg']].to_csv('submission54.csv', \n",
    "                                        index=False, float_format='%.6f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
