{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 50  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불순도낮다 = 분류가 잘 되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n",
    "\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    return [('gini', gini_score)]\n",
    "\n",
    "\n",
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "  \n",
    "def target_encode(trn_series=None,  \n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    \"\"\"\n",
    "    Smoothing은 Daniele Micci-Barreca의 논문에서와 같이 계산됩니다.\n",
    "    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n",
    "    trn_series : pd.Series 형태의 학습할 범주형 피처\n",
    "    tst_series : pd.Series 형태의 테스트할 범주형 피처\n",
    "    target : pd.Series 형태의 타겟 데이터\n",
    "    min_samples_leaf (int) : 범주의 평균을 고려할 최소 샘플\n",
    "    smoothing (int) : 범주 평균과 이전의 균형을 맞추기 위한 스무딩 효과 \n",
    "    \"\"\" \n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    \n",
    "    # 타겟 평균을 계산\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    \n",
    "    # 스무딩 계산\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    \n",
    "    # 모든 타겟 데이터에 평균 적용하기\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # 카운트가 클수록 full_avg가 적어집니다.\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    \n",
    "    # 학습, 테스트 데이터에 평균 적용\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원합니다.\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원합니다.\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge는 인덱스를 유지하지 않으므로 복원합니다.\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "train_df = pd.read_csv(\"data/train.csv\", na_values=\"-1\")\n",
    "test_df = pd.read_csv(\"data/test.csv\", na_values=\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# olivier 커널 참고\n",
    "train_features = [\n",
    "  \"ps_car_13\",       #            : 1571.65 / shadow  609.23\n",
    "  \"ps_reg_03\",       #            : 1408.42 / shadow  511.15\n",
    "  \"ps_ind_05_cat\",   #        : 1387.87 / shadow   84.72\n",
    "  \"ps_ind_03\",       #            : 1219.47 / shadow  230.55\n",
    "  \"ps_ind_15\",       #            :  922.18 / shadow  242.00\n",
    "  \"ps_reg_02\",       #            :  920.65 / shadow  267.50\n",
    "  \"ps_car_14\",       #            :  798.48 / shadow  549.58\n",
    "  \"ps_car_12\",       #            :  731.93 / shadow  293.62\n",
    "  \"ps_car_01_cat\",   #        :  698.07 / shadow  178.72\n",
    "  \"ps_car_07_cat\",   #        :  694.53 / shadow   36.35\n",
    "  \"ps_ind_17_bin\",   #        :  620.77 / shadow   23.15\n",
    "  \"ps_car_03_cat\",   #        :  611.73 / shadow   50.67\n",
    "  \"ps_reg_01\",       #            :  598.60 / shadow  178.57\n",
    "  \"ps_car_15\",       #            :  593.35 / shadow  226.43\n",
    "  \"ps_ind_01\",       #            :  547.32 / shadow  154.58\n",
    "  \"ps_ind_16_bin\",   #        :  475.37 / shadow   34.17\n",
    "  \"ps_ind_07_bin\",   #        :  435.28 / shadow   28.92\n",
    "  \"ps_car_06_cat\",   #        :  398.02 / shadow  212.43\n",
    "  \"ps_car_04_cat\",   #        :  376.87 / shadow   76.98\n",
    "  \"ps_ind_06_bin\",   #        :  370.97 / shadow   36.13\n",
    "  \"ps_car_09_cat\",   #        :  214.12 / shadow   81.38\n",
    "  \"ps_car_02_cat\",   #        :  203.03 / shadow   26.67\n",
    "  \"ps_ind_02_cat\",   #        :  189.47 / shadow   65.68\n",
    "  \"ps_car_11\",       #            :  173.28 / shadow   76.45\n",
    "  \"ps_car_05_cat\",   #        :  172.75 / shadow   62.92\n",
    "  \"ps_calc_09\",      #           :  169.13 / shadow  129.72\n",
    "  \"ps_calc_05\",      #           :  148.83 / shadow  120.68\n",
    "  \"ps_ind_08_bin\",   #        :  140.73 / shadow   27.63\n",
    "  \"ps_car_08_cat\",   #        :  120.87 / shadow   28.82\n",
    "  \"ps_ind_09_bin\",   #         :  113.92 / shadow   27.05\n",
    "  \"ps_ind_04_cat\",   #        :  107.27 / shadow   37.43\n",
    "  \"ps_ind_18_bin\",   #        :   77.42 / shadow   25.97\n",
    "  \"ps_ind_12_bin\",   #        :   39.67 / shadow   15.52\n",
    "  \"ps_ind_14\",       #            :   37.37 / shadow   16.65\n",
    "]\n",
    "# 조합 추가\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('ps_reg_01', 'ps_car_02_cat')\n",
      "1 ('ps_reg_01', 'ps_car_04_cat')\n"
     ]
    }
   ],
   "source": [
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    print(n_c, (f1, f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[ps_reg_01_plus_ps_car_04_cat] = train_df['ps_reg_01].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0.7_1.0                               ps_reg_01_plus_ps_car_02_cat    1 in   0.0\n",
      "1         0.8_1.0\n",
      "2         0.0_1.0\n",
      "3         0.9_1.0\n",
      "4         0.7_1.0\n",
      "           ...   \n",
      "595207    0.5_1.0\n",
      "595208    0.9_1.0\n",
      "595209    0.9_1.0\n",
      "595210    0.9_1.0\n",
      "595211    0.1_0.0\n",
      "Name: ps_reg_01_plus_ps_car_02_cat, Length: 595212, dtype: object\n",
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.10         0.7_0\n",
      "1         0.8_0\n",
      "2         0.0_0\n",
      "3         0.9_0\n",
      "4         0.7_0\n",
      "          ...  \n",
      "595207    0.5_0\n",
      "595208    0.9_0\n",
      "595209    0.9_0\n",
      "595210    0.9_0\n",
      "595211    0.1_0\n",
      "Name: ps_reg_01_plus_ps_car_04_cat, Length: 595212, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 데이터 처리\n",
    "id_train = train_df['id'].values\n",
    "id_test = test_df['id'].values\n",
    "\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()   # 현재 시간\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    print(train_df[name1])\n",
    "    \n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_car_13',\n",
       " 'ps_reg_03',\n",
       " 'ps_ind_05_cat',\n",
       " 'ps_ind_03',\n",
       " 'ps_ind_15',\n",
       " 'ps_reg_02',\n",
       " 'ps_car_14',\n",
       " 'ps_car_12',\n",
       " 'ps_car_01_cat',\n",
       " 'ps_car_07_cat',\n",
       " 'ps_ind_17_bin',\n",
       " 'ps_car_03_cat',\n",
       " 'ps_reg_01',\n",
       " 'ps_car_15',\n",
       " 'ps_ind_01',\n",
       " 'ps_ind_16_bin',\n",
       " 'ps_ind_07_bin',\n",
       " 'ps_car_06_cat',\n",
       " 'ps_car_04_cat',\n",
       " 'ps_ind_06_bin',\n",
       " 'ps_car_09_cat',\n",
       " 'ps_car_02_cat',\n",
       " 'ps_ind_02_cat',\n",
       " 'ps_car_11',\n",
       " 'ps_car_05_cat',\n",
       " 'ps_calc_09',\n",
       " 'ps_calc_05',\n",
       " 'ps_ind_08_bin',\n",
       " 'ps_car_08_cat',\n",
       " 'ps_ind_09_bin',\n",
       " 'ps_ind_04_cat',\n",
       " 'ps_ind_18_bin',\n",
       " 'ps_ind_12_bin',\n",
       " 'ps_ind_14',\n",
       " 'ps_reg_01_plus_ps_car_02_cat',\n",
       " 'ps_reg_01_plus_ps_car_04_cat']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = 0*y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴드 설정\n",
    "K = 5\n",
    "kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBClassifier 파라미터\n",
    "- **min_child_weight**(반드시 튜닝)\n",
    "  - 값이 높아지면 under-fitting 되는 경우가 있다.\n",
    "  - CV를 통해 튜닝되어야 한다.\n",
    "- **max_depth**(반드시 튜닝)\n",
    "  - 트리의 최대 깊이를 정의\n",
    "  - 루트에서 가장 긴 노드의 거리\n",
    "  - Typical Value는 3-10\n",
    "- **gamma**(반드시 튜닝)\n",
    "  - 노드가 split 되기 위한 loss function의 값이 감소하는 최소값을 정의\n",
    "  - gamma 값이 높아질 수록 알고리즘은 보수적으로 변한다.\n",
    "  - loss function의 정의에 따라 적정값이 달라지기때문에 반드시 튜닝해야 한다.\n",
    "- **colsample_bytree**\n",
    "  - 트리를 생성할때 훈련 데이터에서 변수를 샘플링해주는 비율. 보통0.6~0.9\n",
    "- **objective** = 'reg:linear','binary:logistic','multi:softmax','multi:softprob'   - 4가지 존재\n",
    "  -  회귀 경우 'reg'\n",
    "  - binary분류의 경우 'binary',\n",
    "  - 다중분류경우 'multi'- \n",
    "    - 분류된 class를 return하는 경우 'softmax'\n",
    "    - 각 class에 속할 확률을 return하는 경우 'softprob'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 분류기 설정\n",
    "model = XGBClassifier(    \n",
    "                        n_estimators=MAX_ROUNDS,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=LEARNING_RATE, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1.6,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "  Gini =  0.28468979165163677\n",
      "\n",
      "Fold  1\n",
      "  Gini =  0.2825062745155765\n",
      "\n",
      "Fold  2\n",
      "  Gini =  0.2741647405553511\n",
      "\n",
      "Fold  3\n"
     ]
    }
   ],
   "source": [
    "# CV 실행\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n",
    "    \n",
    "    # 폴드에 대한 데이터 생성\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # 데이터 인코드\n",
    "    for f in f_cats:\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_valid[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    # 폴드에 대한 모델 실행\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set=[(X_valid,y_valid)]\n",
    "        fit_model = model.fit( X_train, y_train, \n",
    "                               eval_set=eval_set,\n",
    "                               eval_metric=gini_xgb,\n",
    "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                               verbose=False\n",
    "                             )\n",
    "        print( \"  Best N trees = \", model.best_ntree_limit )\n",
    "        print( \"  Best gini = \", model.best_score )\n",
    "    else:\n",
    "        fit_model = model.fit( X_train, y_train )\n",
    "        \n",
    "    # 폴드에 대한 검증 예측 생성\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    print( \"  Gini = \", eval_gini(y_valid, pred) )\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # 테스트 세트의 예측을 누적\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K  # 테스트 세트 예측의 평균\n",
    "\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스태킹 / 앙상블을위한 검증 예측 저장\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv(DATA_PATH + 'xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 제출 파일 생성\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv(DATA_PATH + 'xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
